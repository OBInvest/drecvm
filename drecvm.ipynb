{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4851321",
      "metadata": {
        "id": "c4851321"
      },
      "source": [
        "![PPGI_UFRJ](https://github.com/zavaleta/Fundamentos_DS/blob/main/imagens/ppgi-ufrj.png?raw=1)\n",
        "# **Fundamentos de Ciência de Dados**\n",
        "\n",
        "> Trabalho Final - 2º Período de 2022\n",
        "\n",
        "### **Disponibilizando Dados sobre Resultados Financeiros de Cias Abertas Enriquecidos com Proveniência para a [OBInvest](https://obinvest.org/)**\n",
        "\n",
        "---\n",
        "\n",
        "**Alunos:** Gilberto Gil | Saulo Andrade Almeida | Valquire Jesus\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tZBqeLEhT_H6",
      "metadata": {
        "id": "tZBqeLEhT_H6"
      },
      "source": [
        "## **FAIRificação**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "z4oia7HvEySA",
      "metadata": {
        "id": "z4oia7HvEySA"
      },
      "outputs": [],
      "source": [
        "#checking version machine architecture, OS, python and all libs used in this notebook\n",
        "import platform as platform\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import conda\n",
        "import pydot\n",
        "import prov\n",
        "\n",
        "def checkingEnvironmentVersions(details=False):\n",
        "\n",
        "    #definnig version of python and all libs used\n",
        "    HOST_MACHINE_ARCHTECTURE_EXPECTED = 'x86_64'\n",
        "    HOST_MACHINE_OS_EXPECTED = 'Linux'\n",
        "    CONDA_VERSION_EXPECTED = '4.14.0'\n",
        "    CONDA_DEFAULT_ENV_EXPECTED = 'drecvmenv'\n",
        "    PYTHON_VERSION_EXPECTED = '3.9.12'\n",
        "    NUMPY_LIB_VERSION_EXPECTED = '1.21.5'\n",
        "    PANDAS_LIB_VERSION_EXPECTED = '1.4.2'\n",
        "    PYDOT_LIB_VERSION_EXPECTED = '1.4.2'\n",
        "    PROV_LIB_VERSION_EXPECTED = '2.0.0'\n",
        "    \n",
        "\n",
        "    if details: \n",
        "        print('Host Machine Architecture:', platform.machine())\n",
        "        print('Host Machine OS:', platform.system())\n",
        "        print('Conda Version:', conda.__version__)\n",
        "        print('Conda default env:', os.environ['CONDA_DEFAULT_ENV'])\n",
        "        print('Python Version:', platform.python_version())\n",
        "        print('NumPy Lib Version:', np.__version__)\n",
        "        print('Pandas Lib Version:', pd.__version__)\n",
        "        print('PyDot Lib Version:', pydot.__version__)\n",
        "        print('Prov Lib Version:', prov.__version__)\n",
        "        \n",
        "    #checking versions\n",
        "    try:\n",
        "        #checking Machine Architecute expected\n",
        "        assert platform.machine() == HOST_MACHINE_ARCHTECTURE_EXPECTED\n",
        "\n",
        "        #checking OS expected\n",
        "        assert platform.system() == HOST_MACHINE_OS_EXPECTED\n",
        "        \n",
        "        #checking conda version\n",
        "        assert conda.__version__ == CONDA_VERSION_EXPECTED\n",
        "        \n",
        "        #checking conda default environment\n",
        "        assert os.environ['CONDA_DEFAULT_ENV'] == CONDA_DEFAULT_ENV_EXPECTED    \n",
        "\n",
        "        #checking python version\n",
        "        assert platform.python_version() == PYTHON_VERSION_EXPECTED\n",
        "\n",
        "        #checking numpy lib version\n",
        "        assert np.__version__ == NUMPY_LIB_VERSION_EXPECTED  \n",
        "\n",
        "        #checking Pandas lib version\n",
        "        assert pd.__version__ == PANDAS_LIB_VERSION_EXPECTED\n",
        "        \n",
        "        #checking pydot version\n",
        "        assert pydot.__version__ == PYDOT_LIB_VERSION_EXPECTED\n",
        "        \n",
        "        #checking prov version\n",
        "        assert prov.__version__ == PROV_LIB_VERSION_EXPECTED\n",
        "    except:\n",
        "        #if any assert fail, or something else get wrong during verification\n",
        "        if details: print('Something is wrong!')\n",
        "        return False\n",
        "    else:\n",
        "        #if pass all asserts\n",
        "        if details: print('All versions are correct!')\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rgNNU7YaUVi1",
      "metadata": {
        "id": "rgNNU7YaUVi1"
      },
      "source": [
        "## **Pré-processamento de Dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "df9be604",
      "metadata": {
        "id": "df9be604"
      },
      "outputs": [],
      "source": [
        "#Utilizado ambiente python 3.9\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def carrega_csv(path, nomes_colunas_data=[]):\n",
        "    return pd.read_csv(path, sep=';', header=0, encoding=\"ISO-8859-1\", parse_dates=nomes_colunas_data)\n",
        "\n",
        "def carrega_csvs_dre(template_path_arquivo, anos):\n",
        "    tempDF = pd.DataFrame() \n",
        "    \n",
        "    for ano in anos:\n",
        "        df_ano_corrente = carrega_csv(template_path_arquivo.format(ano), \n",
        "                                      ['DT_REFER', 'DT_INI_EXERC', 'DT_FIM_EXERC'])\n",
        "        \n",
        "        tempDF = pd.concat([tempDF, df_ano_corrente] , ignore_index=True)\n",
        "        \n",
        "    return tempDF\n",
        "    \n",
        "\n",
        "def carregar_dados_empresas():\n",
        "    return carrega_csv(\"data/cad-emp/cad_cia_aberta.csv\")\n",
        "\n",
        "def lista_todos_anos():\n",
        "    #return [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
        "    return [2020, 2021]\n",
        "\n",
        "def carrega_todos_anos_dre_itr():\n",
        "    return carrega_csvs_dre('data/dre-itr/itr_cia_aberta_DRE_con_{0}.csv', lista_todos_anos())\n",
        "\n",
        "def carrega_todos_anos_dre_dfp():\n",
        "    return carrega_csvs_dre('data/dre-dfp/dfp_cia_aberta_DRE_con_{0}.csv', lista_todos_anos())\n",
        "\n",
        "def carregar_datasets():\n",
        "    companyInfoDF = carregar_dados_empresas()\n",
        "    dreItrDF = carrega_todos_anos_dre_itr()\n",
        "    dreDfpDF = carrega_todos_anos_dre_dfp()\n",
        "    return companyInfoDF, dreItrDF, dreDfpDF\n",
        "\n",
        "def trata_dados_companhias(dataframe_cia):\n",
        "    # TRATAMENTO DO DF CAD_CIA\n",
        "    # filtrar as empresas com cadastro ativo - df cad_cia\n",
        "    dataframe_cia = dataframe_cia[dataframe_cia['SIT'] == 'ATIVO']\n",
        "    # deletar colunas desnecessárias\n",
        "    dataframe_cia = dataframe_cia.drop(['DENOM_SOCIAL', 'DENOM_COMERC', 'DT_REG', 'DT_CONST', 'DT_CANCEL', 'MOTIVO_CANCEL', 'SIT', \n",
        "                   'DT_INI_SIT', 'TP_MERC', 'CATEG_REG', 'DT_INI_CATEG', 'SIT_EMISSOR', 'DT_INI_SIT_EMISSOR', \n",
        "                   'CONTROLE_ACIONARIO', 'TP_ENDER', 'LOGRADOURO', 'COMPL', 'BAIRRO', 'MUN', 'UF', 'PAIS', \n",
        "                   'CEP', 'DDD_TEL', 'TEL', 'DDD_FAX', 'FAX', 'EMAIL', 'TP_RESP', 'RESP', 'DT_INI_RESP', \n",
        "                   'LOGRADOURO_RESP', 'COMPL_RESP', 'BAIRRO_RESP', 'MUN_RESP', 'UF_RESP', 'PAIS_RESP', \n",
        "                   'CEP_RESP', 'DDD_TEL_RESP', 'TEL_RESP', 'DDD_FAX_RESP', 'FAX_RESP', 'EMAIL_RESP', \n",
        "                   'CNPJ_AUDITOR', 'AUDITOR'], axis=1)\n",
        "    \n",
        "    # deletar os registros duplicados, que possuem mesmos cnpj e códigos cvm\n",
        "    dataframe_cia = dataframe_cia.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM'], keep = 'last')\n",
        "    \n",
        "    #TODO:Gerar proveniencia do tratamento de companhias\n",
        "    return dataframe_cia\n",
        "\n",
        "def adiciona_ano(dataframe_dre):\n",
        "    ano = []\n",
        "    \n",
        "    #adicionando as informacoes da coluna de Ano\n",
        "    for i in dataframe_dre.itertuples():\n",
        "        ano.append(i.DT_REFER.year)\n",
        "    \n",
        "    dataframe_dre['ANO'] = ano\n",
        "    \n",
        "    return dataframe_dre\n",
        "\n",
        "def adiciona_trimestre(dataframe_dre):\n",
        "    trimestre =[]\n",
        "    \n",
        "    #adicionando as informacoes da coluna de trimestre\n",
        "    for i in dataframe_dre.itertuples():\n",
        "      if i.DT_REFER.month == 3:\n",
        "        trimestre.append(1)\n",
        "      elif i.DT_REFER.month == 6:\n",
        "        trimestre.append(2)\n",
        "      elif i.DT_REFER.month == 9:\n",
        "        trimestre.append(3)\n",
        "      else:\n",
        "        trimestre.append(4)\n",
        "    \n",
        "    dataframe_dre['TRIMESTRE'] = trimestre\n",
        "    \n",
        "    return dataframe_dre\n",
        "\n",
        "def merge_dre_setor(dataframe_dre, dataframe_cia):\n",
        "    # filtrar os informes da empresas ativas\n",
        "    dataframe_dre = pd.merge(dataframe_dre, dataframe_cia, how = 'inner', on = ['CNPJ_CIA', 'CD_CVM']).reset_index(drop=True)\n",
        "    return dataframe_dre.drop(['VERSAO'], axis=1)  # eliminar coluna desnecessária\n",
        "        \n",
        "def filtrarUltimoExerc(dre):\n",
        "    # Descartando resultados do ano anterior e mantendo apenas o último valor \n",
        "    return dre[dre['ORDEM_EXERC'] == 'ÚLTIMO']\n",
        "    \n",
        "def obter_trimestres_123(dataframe_itr):\n",
        "    # FATIAMENTO DO DF ITR\n",
        "    dataframe_itr = filtrarUltimoExerc(dataframe_itr)\n",
        "    # OBTENÇÃO DO DF TRIMESTRES 1, 2 E 3\n",
        "    # criar o df com informações dos trimestres 1 (1 a 3 mês), 2 (4 a 6 mês) e 3 (6 a 9 mês) - df trim123\n",
        "    return dataframe_itr.loc[lambda dataframe_itr: ((dataframe_itr.DT_REFER.dt.month == 3) | \n",
        "                            ((dataframe_itr.DT_REFER.dt.month == 6) & (dataframe_itr.DT_INI_EXERC.dt.month > 3)) | \n",
        "                            ((dataframe_itr.DT_REFER.dt.month == 9) & (dataframe_itr.DT_INI_EXERC.dt.month > 6))) &\n",
        "                             (dataframe_itr.DT_REFER.dt.year == dataframe_itr.DT_INI_EXERC.dt.year)]\n",
        "\n",
        "def obter_acumulado_trim3(dataframe_itr):\n",
        "    # criar o df com informações acumuladas até o trimestre 3, 01/07/ANO a 30/09/ANO - df_acm3\n",
        "    return dataframe_itr.loc[lambda dataframe_itr: ((dataframe_itr.DT_REFER.dt.month == 9) & \n",
        "                                                   (dataframe_itr.DT_INI_EXERC.dt.month <= 6))]\n",
        "\n",
        "def obter_trimestre_4(dataframe_dfp, dataframe_acm3):\n",
        "    # filtrar os informes com data inicial em jan e data de dim em dez - df acm4\n",
        "    df_acm4 = dataframe_dfp.loc[lambda dataframe_dfp: (dataframe_dfp.DT_REFER.dt.month == 12) & (dataframe_dfp.DT_INI_EXERC.dt.month < 10) &\n",
        "                             (dataframe_dfp.DT_REFER.dt.year == dataframe_dfp.DT_INI_EXERC.dt.year)]\n",
        "    # fazer o merge entre df acumulado 4 e df acumulado 3, mantendo o df acumulado 4 - df trim4\n",
        "    df_trim4 = pd.merge(df_acm4, dataframe_acm3, how='left', on=['CD_CVM', 'CD_CONTA', 'ANO'], suffixes=['_acm4','_acm3'])\n",
        "    # preencher valores VL_CONTA ausentes com 0, informes que não foram enviados por Cias até o trimestre 3\n",
        "    df_trim4.VL_CONTA_acm3.fillna(value=0, inplace=True)\n",
        "    # calcular o valor do trimestre 4, fazendo a subtração entre acumulado anual e o acumulado do trimestre 3\n",
        "    df_trim4['RESULTADO'] = df_trim4['VL_CONTA_acm4'] - df_trim4['VL_CONTA_acm3']\n",
        "    # deletar colunas desnecessárias\n",
        "    df_trim4 = df_trim4.drop(['VL_CONTA_acm4','CNPJ_CIA_acm3', 'DT_REFER_acm3', 'DENOM_CIA_acm3', 'GRUPO_DFP_acm3', \n",
        "                 'MOEDA_acm3', 'ESCALA_MOEDA_acm3', 'ORDEM_EXERC_acm3', 'DT_INI_EXERC_acm3', 'DT_FIM_EXERC_acm3', \n",
        "                 'DS_CONTA_acm3', 'VL_CONTA_acm3', 'ST_CONTA_FIXA_acm3','SETOR_ATIV_acm3'], axis=1)\n",
        "    # renomear as colunas para a concatenação com o df trim123\n",
        "    return df_trim4.rename(columns = {'CNPJ_CIA_acm4':'CNPJ_CIA', 'DT_REFER_acm4':'DT_REFER', \n",
        "                             'DENOM_CIA_acm4':'DENOM_CIA', 'GRUPO_DFP_acm4':'GRUPO_DFP', 'MOEDA_acm4':'MOEDA', \n",
        "                             'ESCALA_MOEDA_acm4':'ESCALA_MOEDA', 'ORDEM_EXERC_acm4':'ORDEM_EXERC', \n",
        "                             'DT_INI_EXERC_acm4':'DT_INI_EXERC', 'DT_FIM_EXERC_acm4':'DT_FIM_EXERC', \n",
        "                             'DS_CONTA_acm4':'DS_CONTA', 'ST_CONTA_FIXA_acm4':'ST_CONTA_FIXA', \n",
        "                             'SETOR_ATIV_acm4':'SETOR_ATIV', 'RESULTADO':'VL_CONTA'})\n",
        "\n",
        "def padronizacao_valor_conta(dataframe_dre):\n",
        "    # PADRONIZAÇÃO DA COLUNA VL_CONTA\n",
        "    # dividir por 1000 os valores em que a escala moeda é unidade\n",
        "    dataframe_dre['VL_CONTA'] = dataframe_dre.apply(lambda x: x.VL_CONTA/1000 if x.ESCALA_MOEDA == 'UNIDADE' \n",
        "                                         else x.VL_CONTA, axis = 1)\n",
        "    \n",
        "    # renomear os dados da coluna escala moeda para o valor mil\n",
        "    dataframe_dre['ESCALA_MOEDA'] = dataframe_dre.ESCALA_MOEDA.replace('UNIDADE', 'MIL')\n",
        "    return dataframe_dre\n",
        "\n",
        "\n",
        "# faz a limpeza dos datasets cad_cia, dre_itr e dre_dfp e retorna o dataset obinvest\n",
        "def criar_dataset_obinvest():\n",
        "    # carrega os datasets \n",
        "    df_cia, df_itr, df_dfp = carregar_datasets()\n",
        "\n",
        "    #adicionar dados de Ano e Trimestres\n",
        "    df_itr = adiciona_ano(df_itr)\n",
        "    df_dfp = adiciona_ano(df_dfp)\n",
        "    \n",
        "    #Tratando dados de companhia\n",
        "    df_cia = trata_dados_companhias(df_cia)\n",
        "    \n",
        "    # fazer merge entre cadastro e informe itr, obtendo o df itr com setor - dfs cad_cia e itr\n",
        "    df_itr_setor = merge_dre_setor(df_itr, df_cia)\n",
        "\n",
        "    #Filtrando dados dos 3 primeiros trimestres e adicionando os campos de ano e \n",
        "    df_trim123 = obter_trimestres_123(df_itr_setor)\n",
        "\n",
        "    # OBTENÇÃO DO DF ACUMULADO TRIMESTRE 3\n",
        "    df_acm3 = obter_acumulado_trim3(df_itr_setor)\n",
        "    \n",
        "    # FATIAMENTO DO DF DFP\n",
        "    # filtrar últimos informes anuais - df dfp\n",
        "    df_dfp = filtrarUltimoExerc(df_dfp)\n",
        "    \n",
        "    # fazer merge entre cadastro e informe itr, obtendo o df dfp com setor - dfs cad_cia e dfp\n",
        "    df_dfp_setor = merge_dre_setor(df_dfp, df_cia)\n",
        "    \n",
        "    # OBTENÇÃO DO DF ACUMULADO TRIMESTRE 4\n",
        "    df_trim4 = obter_trimestre_4(df_dfp_setor, df_acm3)\n",
        "    \n",
        "    # CRIAÇÃO DO DF OBINVEST\n",
        "    # criar o df obinvest, concatenando os informes referentes aos 4 trimestres\n",
        "    df_obinvest = pd.concat([df_trim123, df_trim4])\n",
        "    \n",
        "    # comparar registros antes e depois\n",
        "    print('Antes: Linhas = {0} | Colunas = {1}'.format(df_obinvest.shape[0], df_obinvest.shape[1]))\n",
        "    \n",
        "    # deletar os registros duplicados\n",
        "    df_obinvest.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM', 'CD_CONTA', 'DT_INI_EXERC', 'DT_FIM_EXERC', 'ANO'], \n",
        "                              keep = 'last', inplace=True)\n",
        "    \n",
        "    print('Depois: Linhas = {0} | Colunas = {1}'.format(df_obinvest.shape[0], df_obinvest.shape[1]))\n",
        "    \n",
        "    #Adicionar dado de trimestre\n",
        "    df_obinvest = adiciona_trimestre(df_obinvest)\n",
        "    \n",
        "    #padronizacao valores contas\n",
        "    return padronizacao_valor_conta(df_obinvest)\n",
        "    #return df_obinvest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jj6eHx-iXV2O",
      "metadata": {
        "id": "jj6eHx-iXV2O"
      },
      "source": [
        "## **Proveniência de Dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "d7dfd234",
      "metadata": {
        "id": "d7dfd234"
      },
      "outputs": [],
      "source": [
        "import sys, subprocess, datetime\n",
        "from prov.model import ProvDocument, Namespace\n",
        "from prov.dot import prov_to_dot\n",
        "from IPython.display import Image\n",
        "\n",
        "def gerar_saidas_proveniencia(documento_prov):\n",
        "    entity = \"DRE-CVM-PROV\"\n",
        "    #Generating the outup - a  Provenance Graph\n",
        "    dot = prov_to_dot(documento_prov)\n",
        "    graph = entity+\".png\"\n",
        "    dot.write_png(graph)\n",
        "\n",
        "    #Generating the Serialization - Output XML\n",
        "    documento_prov.serialize(entity + \".xml\", format='xml') \n",
        "\n",
        "    #Generating the Serialization - Output Turtle\n",
        "    documento_prov.serialize(entity + \".ttl\", format='rdf', rdf_format='ttl')\n",
        "\n",
        "def adicionar_namespaces(documento_prov):\n",
        "    # Declaring namespaces for various prefixes used in the excution of Randon Walk Experiment\n",
        "    documento_prov.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')\n",
        "    documento_prov.add_namespace('prov', 'http://www.w3.org/ns/prov#')\n",
        "    documento_prov.add_namespace('void', 'http://vocab.deri.ie/void#')\n",
        "    documento_prov.add_namespace('ufrj', 'https://www.ufrj.br')\n",
        "    documento_prov.add_namespace('cvm', 'https://www.gov.br/cvm/pt-br')\n",
        "    documento_prov.add_namespace('cvm-cademp', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/CAD/DADOS/')\n",
        "    documento_prov.add_namespace('cvm-dre-itr-2021-zip', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
        "    return documento_prov\n",
        "\n",
        "def criar_agentes(documento_prov):\n",
        "    \n",
        "    #criando agentes\n",
        "    dagnts={}\n",
        "    dagnts[\"ag-cvm\"] = documento_prov.agent(\"cvm:CVM\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Comissão de Valores Mobiliários\"})\n",
        "    dagnts[\"ag-ufrj\"] = documento_prov.agent(\"ufrj:UFRJ\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Universidade Federal do Rio de Janeiro\"})\n",
        "    dagnts[\"ag-ppgi\"] = documento_prov.agent(\"ufrj:PPGI\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Programa de Pós Graduação em Informática\"})\n",
        "    dagnts[\"ag-mai712\"] = documento_prov.agent(\"ufrj:MAI712\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Disciplina de Fundamentos de Ciências de Dados\"})\n",
        "    dagnts[\"ag-grupo2\"] = documento_prov.agent(\"ufrj:GRUPO2\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Grupo 02 para o trabalho final\"})\n",
        "    dagnts[\"ag-aluno-gil\"] = documento_prov.agent(\"ufrj:Saulo\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Gilberto Gil Fidelis Gomes Passos\", \"foaf:mbox\":\"gilbertogilfgp@gmail.com\"})\n",
        "    dagnts[\"ag-aluno-saulo\"] = documento_prov.agent(\"ufrj:Gil\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Saulo Andrade Almeida\", \"foaf:mbox\":\"sauloandrade@gmail.com\"})\n",
        "    dagnts[\"ag-aluno-valquire\"] = documento_prov.agent(\"ufrj:Valquire\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Valquire da Silva de Jesus\", \"foaf:mbox\":\"valquirej@gmail.com\"})\n",
        "    return dagnts\n",
        "\n",
        "def associar_agentes_ufrj(dicionario_agentes):\n",
        "    dicionario_agentes[\"ag-ppgi\"].actedOnBehalfOf(dicionario_agentes[\"ag-ufrj\"])\n",
        "    dicionario_agentes[\"ag-mai712\"].actedOnBehalfOf(dicionario_agentes[\"ag-ppgi\"])\n",
        "    dicionario_agentes[\"ag-grupo2\"].actedOnBehalfOf(dicionario_agentes[\"ag-mai712\"])\n",
        "    dicionario_agentes[\"ag-aluno-gil\"].actedOnBehalfOf(dicionario_agentes[\"ag-grupo2\"])\n",
        "    dicionario_agentes[\"ag-aluno-saulo\"].actedOnBehalfOf(dicionario_agentes[\"ag-grupo2\"])\n",
        "    dicionario_agentes[\"ag-aluno-valquire\"].actedOnBehalfOf(dicionario_agentes[\"ag-grupo2\"])\n",
        "\n",
        "def criar_atividades_iniciais(documento_prov):\n",
        "    #criando atividades\n",
        "    dativs={}\n",
        "    dativs[\"at-create-ds\"] = documento_prov.activity(\"cvm:create-dataset\")\n",
        "    return dativs\n",
        "    \n",
        "def criar_entidades_iniciais(documento_prov):\n",
        "    #criando atividades\n",
        "    dents={}\n",
        "    dents[\"ent-cademp-ds\"] = documento_prov.entity('cvm-cademp:cad_cia_aberta.csv', {'prov:label': 'Dataset com dados cadastrais das empresas listadas na CVM', 'prov:type': 'void:Dataset'})\n",
        "    dents[\"ent-dreitr\"] = documento_prov.entity('cvm:dre-itr', {'prov:label': 'Documento que representa o conceito de DREs do tipo Trimestral', 'prov:type': 'foaf:Document'})\n",
        "    dents[\"ent-dredfp\"] = documento_prov.entity('cvm:dre-dfp', {'prov:label': 'Documento que representa o conceito de DREs do tipo Anual', 'prov:type': 'foaf:Document'})\n",
        "    dents[\"ent-dreitr2021-zip\"] = documento_prov.entity('cvm-dre-itr-2021-zip:itr_cia_aberta_2021.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2021', 'prov:type': 'foaf:Document'})\n",
        "        \n",
        "    return dents\n",
        "    \n",
        "def associar_agentes_atividades_entidades_iniciais(documento_prov, dicionario_agentes, \n",
        "                                                   dicionario_atividades, dicionario_entidades):\n",
        "    \n",
        "    #Associar a atividade de gerar dataset com o agente CVM\n",
        "    documento_prov.wasAssociatedWith(dicionario_atividades[\"at-create-ds\"], \n",
        "                                     dicionario_agentes[\"ag-cvm\"])\n",
        "    \n",
        "    #Associando os datasets com a atividade de gerar dataset da CVM\n",
        "    documento_prov.wasGeneratedBy(dicionario_entidades[\"ent-cademp-ds\"], \n",
        "                                  dicionario_atividades[\"at-create-ds\"])\n",
        "    documento_prov.wasGeneratedBy(dicionario_entidades[\"ent-dreitr\"], \n",
        "                                  dicionario_atividades[\"at-create-ds\"])    \n",
        "    documento_prov.wasGeneratedBy(dicionario_entidades[\"ent-dredfp\"], \n",
        "                                  dicionario_atividades[\"at-create-ds\"])\n",
        "    \n",
        "    #Associando ZIPs das DREs ITR e DFP com as entidaes de Datasets genericos\n",
        "    documento_prov.wasDerivedFrom(dicionario_entidades[\"ent-dreitr2021-zip\"], \n",
        "                                  dicionario_entidades[\"ent-dreitr\"])\n",
        "\n",
        "\n",
        "def inicializaProveniencia():\n",
        "    # Creating an empty provenance document\n",
        "    doc_prov = ProvDocument()\n",
        "\n",
        "    #criando os namespaces do documento de proveniencia\n",
        "    doc_prov = adicionar_namespaces(doc_prov)\n",
        "    \n",
        "    #criando agentes\n",
        "    agentes_dic = criar_agentes(doc_prov)\n",
        "    \n",
        "    #criando as hierarquia de agentes\n",
        "    associar_agentes_ufrj(agentes_dic)\n",
        "    \n",
        "    #criando atividades iniciais\n",
        "    atividades_dic = criar_atividades_iniciais(doc_prov)\n",
        "    \n",
        "    #criando entidades iniciais\n",
        "    entidades_dic = criar_entidades_iniciais(doc_prov)\n",
        "    \n",
        "    #associacoes inicias da proveniencia\n",
        "    associar_agentes_atividades_entidades_iniciais(doc_prov, agentes_dic, atividades_dic, entidades_dic)\n",
        "    \n",
        "    #criando entidades iniciais\n",
        "    return doc_prov, agentes_dic, atividades_dic, entidades_dic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ds8Kte_9X8Sm",
      "metadata": {
        "id": "Ds8Kte_9X8Sm"
      },
      "source": [
        "## **Análise de Dados**\n",
        "### **Análise Inicial dos Dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "yWzWQts26z5m",
      "metadata": {
        "id": "yWzWQts26z5m"
      },
      "outputs": [],
      "source": [
        "def analiseInicialDataset(dataframe_obinvest):\n",
        "    #print(dataframe_obinvest.info())\n",
        "    print(dataframe_obinvest.shape)\n",
        "    #print(dataframe_obinvest.isnull().sum())\n",
        "    #print(dataframe_obinvest.describe())\n",
        "    #print(dataframe_obinvest.columns)\n",
        "    #print(dataframe_obinvest.DT_REFER.value_counts())\n",
        "    #print(dataframe_obinvest.ESCALA_MOEDA.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67ebdfbe",
      "metadata": {
        "id": "67ebdfbe"
      },
      "source": [
        "### **Análise Estatística dos Dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "N5hJH1HA69cq",
      "metadata": {
        "id": "N5hJH1HA69cq"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "def analiseEstatisticaDataset(dataFrameObinvest):\n",
        "    print('Rodando experimento de dataset estatisticos')\n",
        "    #sns.displot(dataFrameObinvest['VL_CONTA'], bins=30)\n",
        "    #fig1 = px.scatter(dataFrameObinvest, x = dataFrameObinvest.CD_CONTA.index, y = dataFrameObinvest.ANO, \n",
        "    #                  color=dataFrameObinvest.CD_CONTA)\n",
        "    #fig1.show()\n",
        "    contas = dataFrameObinvest.groupby(['CD_CONTA', 'SETOR_ATIV', 'ANO', 'TRIMESTRE'])['VL_CONTA'].sum()\n",
        "    print(contas)\n",
        "    print(dataFrameObinvest.columns)\n",
        "    #print(dataFrameObinvest.head())\n",
        "    \n",
        "    #resposta=dataFrameObinvest.loc[dataFrameObinvest['DT_INI_EXERC']=='2019-07-01']\n",
        "    #print(resposta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a8c2191",
      "metadata": {
        "id": "1a8c2191"
      },
      "source": [
        "## **Execução Principal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "d04b83e9",
      "metadata": {
        "id": "d04b83e9"
      },
      "outputs": [],
      "source": [
        "def executaExperimento():\n",
        "    doc_prov, dic_agentes , dic_atividades, dic_entidades = inicializaProveniencia()\n",
        "    df_obinvest = criar_dataset_obinvest()\n",
        "    analiseInicialDataset(df_obinvest)\n",
        "    analiseEstatisticaDataset(df_obinvest)\n",
        "    gerar_saidas_proveniencia(doc_prov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "42cb0ff2",
      "metadata": {
        "id": "42cb0ff2",
        "outputId": "e5f6864d-8b80-4b85-fd14-837ca9646cb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antes: Linhas = 133703 | Colunas = 16\n",
            "Depois: Linhas = 108569 | Colunas = 16\n",
            "(108569, 17)\n",
            "Rodando experimento de dataset estatisticos\n",
            "CD_CONTA    SETOR_ATIV                                  ANO   TRIMESTRE\n",
            "3.01        Agricultura (Açúcar, Álcool e Cana)         2020  1            4.644205e+06\n",
            "                                                              2            9.718834e+06\n",
            "                                                              3            1.358116e+07\n",
            "                                                              4            5.366045e+06\n",
            "                                                        2021  1            6.830146e+06\n",
            "                                                                               ...     \n",
            "3.99.02.07  Emp. Adm. Part. - Intermediação Financeira  2021  2            4.998000e-02\n",
            "                                                              3            1.176100e-01\n",
            "                                                              4            5.157000e-02\n",
            "3.99.02.08  Emp. Adm. Part. - Intermediação Financeira  2020  3            1.465300e-01\n",
            "                                                        2021  3            1.176100e-01\n",
            "Name: VL_CONTA, Length: 20819, dtype: float64\n",
            "Index(['CNPJ_CIA', 'DT_REFER', 'DENOM_CIA', 'CD_CVM', 'GRUPO_DFP', 'MOEDA',\n",
            "       'ESCALA_MOEDA', 'ORDEM_EXERC', 'DT_INI_EXERC', 'DT_FIM_EXERC',\n",
            "       'CD_CONTA', 'DS_CONTA', 'VL_CONTA', 'ST_CONTA_FIXA', 'ANO',\n",
            "       'SETOR_ATIV', 'TRIMESTRE'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    #if(checkingEnvironmentVersions(True)):\n",
        "        executaExperimento()\n",
        "        \n",
        "main() # condição suspensa para poder rodar no notebook local\n",
        "\n",
        "#Image(\"DRE-CVM-PROV.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "drecvm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}