{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4851321",
   "metadata": {
    "id": "c4851321"
   },
   "source": [
    "![PPGI_UFRJ](https://github.com/zavaleta/Fundamentos_DS/blob/main/imagens/ppgi-ufrj.png?raw=1)\n",
    "# **DRECVM**\n",
    "\n",
    "### **Providing Data on Financial Results of Public Companies Enriched with Provenance for [OBInvest](https://obinvest.org/)**\n",
    "\n",
    "---\n",
    "\n",
    "**Authors:** Gilberto Gil | Saulo Almeida | Valquire Jesus | Sergio Serra | Jorge Zavaleta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tZBqeLEhT_H6",
   "metadata": {
    "id": "tZBqeLEhT_H6"
   },
   "source": [
    "## **FAIRification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4oia7HvEySA",
   "metadata": {
    "id": "z4oia7HvEySA"
   },
   "outputs": [],
   "source": [
    "#checking version machine architecture, OS, python and all libs used in this notebook\n",
    "import platform\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import conda\n",
    "import pydot\n",
    "import prov\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import plotly\n",
    "\n",
    "def verify_libs_environment_versions(details=False):\n",
    "\n",
    "    #definnig version of python and all libs used\n",
    "    HOST_MACHINE_ARCHTECTURE_EXPECTED = 'x86_64'\n",
    "    HOST_MACHINE_OS_EXPECTED = 'Linux'\n",
    "    CONDA_VERSION_EXPECTED = '22.9.0'\n",
    "    CONDA_DEFAULT_ENV_EXPECTED = 'drecvmenv'\n",
    "    PYTHON_VERSION_EXPECTED = '3.9.12'\n",
    "    NUMPY_LIB_VERSION_EXPECTED = '1.21.5'\n",
    "    PANDAS_LIB_VERSION_EXPECTED = '1.4.2'\n",
    "    PYDOT_LIB_VERSION_EXPECTED = '1.4.2'\n",
    "    PROV_LIB_VERSION_EXPECTED = '2.0.0'\n",
    "    SEABORN_LIB_VERSION_EXPECTED = '0.11.2'\n",
    "    MATPLOTLIB_LIB_VERSION_EXPECTED = '3.5.1'\n",
    "    PLOTLY_LIB_VERSION_EXPECTED = '5.6.0'\n",
    "    \n",
    "    \n",
    "\n",
    "    if details: \n",
    "        print('Host Machine Architecture:', platform.machine())\n",
    "        print('Host Machine OS:', platform.system())\n",
    "        print('Conda Version:', conda.__version__)\n",
    "        print('Conda default env:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "        print('Python Version:', platform.python_version())\n",
    "        print('NumPy Lib Version:', numpy.__version__)\n",
    "        print('Pandas Lib Version:', pandas.__version__)\n",
    "        print('PyDot Lib Version:', pydot.__version__)\n",
    "        print('Prov Lib Version:', prov.__version__)\n",
    "        print('Seaborn Lib Version:', seaborn.__version__)\n",
    "        print('Matplotlib Lib Version:', matplotlib.__version__)\n",
    "        print('Plotly Lib Version:', plotly.__version__)\n",
    "        \n",
    "        \n",
    "    #checking versions\n",
    "    try:\n",
    "        #checking Machine Architecute expected\n",
    "        assert platform.machine() == HOST_MACHINE_ARCHTECTURE_EXPECTED\n",
    "\n",
    "        #checking OS expected\n",
    "        assert platform.system() == HOST_MACHINE_OS_EXPECTED\n",
    "        \n",
    "        #checking conda version\n",
    "        assert conda.__version__ == CONDA_VERSION_EXPECTED\n",
    "        \n",
    "        #checking conda default environment\n",
    "        assert os.environ['CONDA_DEFAULT_ENV'] == CONDA_DEFAULT_ENV_EXPECTED    \n",
    "\n",
    "        #checking python version\n",
    "        assert platform.python_version() == PYTHON_VERSION_EXPECTED\n",
    "\n",
    "        #checking numpy lib version\n",
    "        assert numpy.__version__ == NUMPY_LIB_VERSION_EXPECTED  \n",
    "\n",
    "        #checking Pandas lib version\n",
    "        assert pandas.__version__ == PANDAS_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking pydot version\n",
    "        assert pydot.__version__ == PYDOT_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking prov version\n",
    "        assert prov.__version__ == PROV_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking seaborn version\n",
    "        assert seaborn.__version__ == SEABORN_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking matplotlib version\n",
    "        assert matplotlib.__version__ == MATPLOTLIB_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking plotly version\n",
    "        assert plotly.__version__ == PLOTLY_LIB_VERSION_EXPECTED\n",
    "    except:\n",
    "        #if any assert fail, or something else get wrong during verification\n",
    "        if details: print('Somethings is wrong. Verify environment and libs versions!')\n",
    "        return False\n",
    "    else:\n",
    "        #if pass all asserts\n",
    "        if details: print('All environment and libs versions are correct!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rgNNU7YaUVi1",
   "metadata": {
    "id": "rgNNU7YaUVi1"
   },
   "source": [
    "## **Data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9be604",
   "metadata": {
    "id": "df9be604"
   },
   "outputs": [],
   "source": [
    "#Using python 3.9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, subprocess, datetime\n",
    "\n",
    "def load_csv(path, date_columns_names=[]):\n",
    "    return pd.read_csv(path, sep=';', header=0, encoding=\"ISO-8859-1\", parse_dates=date_columns_names)\n",
    "\n",
    "def load_csvs_dre(template_path_file, years):\n",
    "    tempDF = pd.DataFrame() \n",
    "    \n",
    "    for year in years:\n",
    "        df_current_year = load_csv(template_path_file.format(year), \n",
    "                                      ['DT_REFER', 'DT_INI_EXERC', 'DT_FIM_EXERC'])\n",
    "        \n",
    "        tempDF = pd.concat([tempDF, df_current_year] , ignore_index=True)\n",
    "        \n",
    "    return tempDF\n",
    "    \n",
    "\n",
    "def load_companies_data():\n",
    "    return load_csv(\"data/cad-emp/cad_cia_aberta.csv\")\n",
    "\n",
    "def list_all_years():\n",
    "    return [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "def load_all_dre_itr_years_data():\n",
    "    return load_csvs_dre('data/dre-itr/itr_cia_aberta_DRE_con_{0}.csv', list_all_years())\n",
    "\n",
    "def load_all_dre_dfp_years_data():\n",
    "    return load_csvs_dre('data/dre-dfp/dfp_cia_aberta_DRE_con_{0}.csv', list_all_years())\n",
    "\n",
    "def load_all_datasets():\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    companyInfoDF = load_companies_data()\n",
    "    dreItrDF = load_all_dre_itr_years_data()\n",
    "    dreDfpDF = load_all_dre_dfp_years_data()\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-load-ds\"] = doc_prov.activity(\"ufrj:load_all_datasets\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-load-ds\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-cademp-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2011-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2012-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2013-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2014-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2015-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2016-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2017-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2018-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2019-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2020-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dreitr2021-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2011-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2012-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2013-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2014-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2015-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2016-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2017-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2018-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2019-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2020-ds\"])\n",
    "    doc_prov.used(dict_activities[\"act-load-ds\"],dict_entities[\"ent-dredfp2021-ds\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-cademp-df\"] = doc_prov.entity('obinvest:df_cia', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das empresas'})\n",
    "    dict_entities[\"ent-dreitr-df\"] = doc_prov.entity('obinvest:df_itr', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs trimestrais'})\n",
    "    dict_entities[\"ent-dredfp-df\"] = doc_prov.entity('obinvest:df_dfp', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs anuais'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-cademp-df\"], dict_activities[\"act-load-ds\"])    \n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitr-df\"], dict_activities[\"act-load-ds\"])    \n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dredfp-df\"], dict_activities[\"act-load-ds\"])    \n",
    "    \n",
    "    return companyInfoDF, dreItrDF, dreDfpDF\n",
    "\n",
    "def sanitaze_company_data(dataframe_cia):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    #DF SANITIZATION OF CAD_CIA\n",
    "    #filter only active companies - df cad_cia\n",
    "    dataframe_cia = dataframe_cia[dataframe_cia['SIT'] == 'ATIVO']\n",
    "    #remove unnecessary columns\n",
    "    dataframe_cia = dataframe_cia.drop(['DENOM_SOCIAL', 'DENOM_COMERC', 'DT_REG', 'DT_CONST', 'DT_CANCEL', 'MOTIVO_CANCEL', 'SIT', \n",
    "                   'DT_INI_SIT', 'TP_MERC', 'CATEG_REG', 'DT_INI_CATEG', 'SIT_EMISSOR', 'DT_INI_SIT_EMISSOR', \n",
    "                   'CONTROLE_ACIONARIO', 'TP_ENDER', 'LOGRADOURO', 'COMPL', 'BAIRRO', 'MUN', 'UF', 'PAIS', \n",
    "                   'CEP', 'DDD_TEL', 'TEL', 'DDD_FAX', 'FAX', 'EMAIL', 'TP_RESP', 'RESP', 'DT_INI_RESP', \n",
    "                   'LOGRADOURO_RESP', 'COMPL_RESP', 'BAIRRO_RESP', 'MUN_RESP', 'UF_RESP', 'PAIS_RESP', \n",
    "                   'CEP_RESP', 'DDD_TEL_RESP', 'TEL_RESP', 'DDD_FAX_RESP', 'FAX_RESP', 'EMAIL_RESP', \n",
    "                   'CNPJ_AUDITOR', 'AUDITOR'], axis=1)\n",
    "    \n",
    "    #remove duplicate records with same cnpj and cvm ID\n",
    "    dataframe_cia = dataframe_cia.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM'], keep = 'last')\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-sanatize-company-data\"] = doc_prov.activity(\"ufrj:sanitaze_company_data\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-sanatize-company-data\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-sanatize-company-data\"],dict_entities[\"ent-cademp-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-cademp-tratado-df\"] = doc_prov.entity('obinvest:df_cia_tratado', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das empresas ativas, apenas com os campos necessarios'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-cademp-tratado-df\"], dict_activities[\"act-sanatize-company-data\"])    \n",
    "    \n",
    "    return dataframe_cia\n",
    "\n",
    "def add_year(dataframe_dre):\n",
    "    ano = []\n",
    "    \n",
    "    #adding year column\n",
    "    for i in dataframe_dre.itertuples():\n",
    "        ano.append(i.DT_REFER.year)\n",
    "    \n",
    "    dataframe_dre['ANO'] = ano\n",
    "    \n",
    "    return dataframe_dre\n",
    "\n",
    "def adding_year_field_to_dre(dataframe_dre_itr, dataframe_dre_dfp):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    dreItr = add_year(dataframe_dre_itr)\n",
    "    dreDfp = add_year(dataframe_dre_dfp)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-adicionar-ano\"] = doc_prov.activity(\"ufrj:adding_year_field_to_dre\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-adicionar-ano\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-adicionar-ano\"],dict_entities[\"ent-dreitr-df\"])\n",
    "    doc_prov.used(dict_activities[\"act-adicionar-ano\"],dict_entities[\"ent-dredfp-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitr-ano-df\"] = doc_prov.entity('obinvest:df_itr_ano', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs trimestrais, adicionada a coluna ano'})\n",
    "    dict_entities[\"ent-dredfp-ano-df\"] = doc_prov.entity('obinvest:df_dfp_ano', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs anuais, adicionada a coluna ano'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitr-ano-df\"], dict_activities[\"act-adicionar-ano\"])    \n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dredfp-ano-df\"], dict_activities[\"act-adicionar-ano\"])      \n",
    "    \n",
    "    return dreItr, dreDfp\n",
    "\n",
    "def merge_dre_itr_sector(dataframe_dre, dataframe_cia):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "\n",
    "    dfTemp = merge_dre_sector(dataframe_dre, dataframe_cia)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-merge-dreitr-sector\"] = doc_prov.activity(\"ufrj:merge_dre_itr_sector\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-merge-dreitr-sector\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-merge-dreitr-sector\"],dict_entities[\"ent-dreitr-ano-df\"])\n",
    "    doc_prov.used(dict_activities[\"act-merge-dreitr-sector\"],dict_entities[\"ent-cademp-tratado-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitf-sector-df\"] = doc_prov.entity('obinvest:df_itr_sector', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs trimestrais, adicionado o campo de sector da empresa'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitf-sector-df\"], dict_activities[\"act-merge-dreitr-sector\"])    \n",
    "\n",
    "    return dfTemp\n",
    "\n",
    "def merge_dre_dfp_sector(dataframe_dre, dataframe_cia):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "\n",
    "    dfTemp = merge_dre_sector(dataframe_dre, dataframe_cia)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-merge-dredfp-sector\"] = doc_prov.activity(\"ufrj:merge_dre_dfp_sector\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-merge-dredfp-sector\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-merge-dredfp-sector\"],dict_entities[\"ent-dredfp-exerc-df\"])\n",
    "    doc_prov.used(dict_activities[\"act-merge-dredfp-sector\"],dict_entities[\"ent-cademp-tratado-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dredfp-sector-df\"] = doc_prov.entity('obinvest:df_dfp_sector', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs anuais, adicionado o campo de sector da empresa'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dredfp-sector-df\"], dict_activities[\"act-merge-dredfp-sector\"])    \n",
    "\n",
    "    return dfTemp\n",
    "\n",
    "def merge_dre_sector(dataframe_dre, dataframe_cia):    \n",
    "    #filter only active companies\n",
    "    dataframe_dre = pd.merge(dataframe_dre, dataframe_cia, how = 'inner', on = ['CNPJ_CIA', 'CD_CVM']).reset_index(drop=True)\n",
    "    return dataframe_dre.drop(['VERSAO'], axis=1)  #remove unnecessary column\n",
    "\n",
    "def filter_last_year(dre):\n",
    "    #maintain only last result \n",
    "    return dre[dre['ORDEM_EXERC'] == 'ÚLTIMO']\n",
    "\n",
    "def filter_last_dfp_year(dre):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    dfTemp = filter_last_year(dre)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-filtrar-exerc-dfp\"] = doc_prov.activity(\"ufrj:filter_last_dfp_year\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-filtrar-exerc-dfp\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-filtrar-exerc-dfp\"],dict_entities[\"ent-dredfp-ano-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dredfp-exerc-df\"] = doc_prov.entity('obinvest:df_dfp_ultimo_exerc', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs anuais apenas do ano relativo ao dataset'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dredfp-exerc-df\"], dict_activities[\"act-filtrar-exerc-dfp\"])\n",
    "    \n",
    "    return dfTemp\n",
    "    \n",
    "def filter_quarters_123(dataframe_itr):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    # slicing ITR DF\n",
    "    dataframe_itr = filter_last_year(dataframe_itr)\n",
    "    # filtering quarters 1, 2 and 3\n",
    "    # create df with quarter info 1 (1 to 3 month), 2 (4 to 6 month) e 3 (6 to 9 month) - df quarter123\n",
    "    dfTemp = dataframe_itr.loc[lambda dataframe_itr: ((dataframe_itr.DT_REFER.dt.month == 3) | \n",
    "                            ((dataframe_itr.DT_REFER.dt.month == 6) & (dataframe_itr.DT_INI_EXERC.dt.month > 3)) | \n",
    "                            ((dataframe_itr.DT_REFER.dt.month == 9) & (dataframe_itr.DT_INI_EXERC.dt.month > 6))) &\n",
    "                             (dataframe_itr.DT_REFER.dt.year == dataframe_itr.DT_INI_EXERC.dt.year)]\n",
    "\n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-filter-quarters123\"] = doc_prov.activity(\"ufrj:filter_quarters_123\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-filter-quarters123\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-filter-quarters123\"],dict_entities[\"ent-dreitf-sector-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitf-trim123-df\"] = doc_prov.entity('obinvest:df_trim123', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs trimestrais dos trimestres 1, 2 e 3'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitf-trim123-df\"], dict_activities[\"act-filter-quarters123\"])\n",
    "    \n",
    "    return dfTemp\n",
    "\n",
    "def filter_quarter3_cumulative(dataframe_itr):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    # create df with cumulative value of third trimester, 07/01/YEAR a 09/30/YEAR - df_acm3\n",
    "    dfTemp = dataframe_itr.loc[lambda dataframe_itr: ((dataframe_itr.DT_REFER.dt.month == 9) & \n",
    "                                                    (dataframe_itr.DT_INI_EXERC.dt.month <= 6)) &\n",
    "                             (dataframe_itr.DT_REFER.dt.year == dataframe_itr.DT_INI_EXERC.dt.year)]\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-obter-acm3\"] = doc_prov.activity(\"ufrj:filter_quarter3_cumulative\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-obter-acm3\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-obter-acm3\"],dict_entities[\"ent-dreitf-sector-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitf-acm3-df\"] = doc_prov.entity('obinvest:df_acm3', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com valores das DREs acumuladas dos tres primeiros trimestres'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitf-acm3-df\"], dict_activities[\"act-obter-acm3\"])\n",
    "    \n",
    "    return dfTemp\n",
    "    \n",
    "def filter_quarter_4(dataframe_dfp, dataframe_acm3):\n",
    "\n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    #filter records with end month in december - df acm4\n",
    "    df_acm4 = dataframe_dfp.loc[lambda dataframe_dfp: (dataframe_dfp.DT_REFER.dt.month == 12) & \n",
    "                             (dataframe_dfp.DT_REFER.dt.year == dataframe_dfp.DT_INI_EXERC.dt.year)]\n",
    "    #merge cumulative quarter 4 df and cumulative quarter 3, mantaining cumulative quarter df 4 - df trim4\n",
    "    df_trim4 = pd.merge(df_acm4, dataframe_acm3, how='left', on=['CD_CVM', 'CD_CONTA', 'ANO'], suffixes=['_acm4','_acm3'])\n",
    "    #fill values VL_CONTA absent with 0, values not sent until third quarter\n",
    "    df_trim4.VL_CONTA_acm3.fillna(value=0, inplace=True)\n",
    "    # calculate 4 quarter value, subtracting anual cumulative and third quarter cumulated\n",
    "    df_trim4['RESULTADO'] = df_trim4['VL_CONTA_acm4'] - df_trim4['VL_CONTA_acm3']\n",
    "    # drop unnecessaries columns\n",
    "    df_trim4 = df_trim4.drop(['VL_CONTA_acm4','CNPJ_CIA_acm3', 'DT_REFER_acm3', 'DENOM_CIA_acm3', 'GRUPO_DFP_acm3', \n",
    "                 'MOEDA_acm3', 'ESCALA_MOEDA_acm3', 'ORDEM_EXERC_acm3', 'DT_INI_EXERC_acm3', 'DT_FIM_EXERC_acm3', \n",
    "                 'DS_CONTA_acm3', 'VL_CONTA_acm3', 'ST_CONTA_FIXA_acm3','SETOR_ATIV_acm3'], axis=1)\n",
    "    # rename columns to concatenate with df trim123\n",
    "    dtTemp = df_trim4.rename(columns = {'CNPJ_CIA_acm4':'CNPJ_CIA', 'DT_REFER_acm4':'DT_REFER', \n",
    "                             'DENOM_CIA_acm4':'DENOM_CIA', 'GRUPO_DFP_acm4':'GRUPO_DFP', 'MOEDA_acm4':'MOEDA', \n",
    "                             'ESCALA_MOEDA_acm4':'ESCALA_MOEDA', 'ORDEM_EXERC_acm4':'ORDEM_EXERC', \n",
    "                             'DT_INI_EXERC_acm4':'DT_INI_EXERC', 'DT_FIM_EXERC_acm4':'DT_FIM_EXERC', \n",
    "                             'DS_CONTA_acm4':'DS_CONTA', 'ST_CONTA_FIXA_acm4':'ST_CONTA_FIXA', \n",
    "                             'SETOR_ATIV_acm4':'SETOR_ATIV', 'RESULTADO':'VL_CONTA'})\n",
    "\n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-obter-trim4\"] = doc_prov.activity(\"ufrj:filter_quarter_4\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-merge-dredfp-sector\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-obter-trim4\"],dict_entities[\"ent-dredfp-sector-df\"])\n",
    "    doc_prov.used(dict_activities[\"act-obter-trim4\"],dict_entities[\"ent-dreitf-acm3-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreirt-trim4-df\"] = doc_prov.entity('obinvest:df_trim4', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs do 4 trimestre, subtraindo DFP anual pelo acumulado dos tres primeiros'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreirt-trim4-df\"], dict_activities[\"act-obter-trim4\"])    \n",
    "    \n",
    "    return dtTemp\n",
    "\n",
    "def concatenate_quarters(df_trim123, df_trim4):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    dfTemp = pd.concat([df_trim123, df_trim4])\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-concact-trim\"] = doc_prov.activity(\"ufrj:concatenate_quarters\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-concact-trim\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-concact-trim\"],dict_entities[\"ent-dreirt-trim4-df\"])\n",
    "    doc_prov.used(dict_activities[\"act-concact-trim\"],dict_entities[\"ent-dreitf-trim123-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreirt-trim1234-df\"] = doc_prov.entity('obinvest:df_trim1234', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs de todos os trimestres'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreirt-trim1234-df\"], dict_activities[\"act-concact-trim\"])    \n",
    "    \n",
    "    \n",
    "    return dfTemp\n",
    "\n",
    "def remove_duplicate_records(df_obinvest_trim1234):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    dfTemp = df_obinvest_trim1234.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM', 'CD_CONTA', 'DT_INI_EXERC', 'DT_FIM_EXERC', 'ANO'], \n",
    "                              keep = 'last')\n",
    "\n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-remove-dup\"] = doc_prov.activity(\"ufrj:remove_duplicate_records\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-remove-dup\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-remove-dup\"],dict_entities[\"ent-dreirt-trim1234-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitf-tratado-df\"] = doc_prov.entity('obinvest:df_obinvest_tratado', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com valores das DREs acumuladas dos tres primeiros trimestres'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitf-tratado-df\"], dict_activities[\"act-remove-dup\"])\n",
    "    \n",
    "    return dfTemp\n",
    "\n",
    "def adding_quarter_field(dataframe_dre):\n",
    "    \n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    trimestre =[]\n",
    "    \n",
    "    #adding quater column\n",
    "    for i in dataframe_dre.itertuples():\n",
    "      if i.DT_REFER.month == 3:\n",
    "        trimestre.append(1)\n",
    "      elif i.DT_REFER.month == 6:\n",
    "        trimestre.append(2)\n",
    "      elif i.DT_REFER.month == 9:\n",
    "        trimestre.append(3)\n",
    "      else:\n",
    "        trimestre.append(4)\n",
    "    \n",
    "    dataframe_dre = dataframe_dre.assign(TRIMESTRE=trimestre)\n",
    "    dataframe_dre.reset_index(drop=True)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-adicionar-trimestre\"] = doc_prov.activity(\"ufrj:adding_quarter_field\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-adicionar-trimestre\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-adicionar-trimestre\"],dict_entities[\"ent-dreitf-tratado-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-dreitr-trimestre-df\"] = doc_prov.entity('obinvest:df_obinvest_campo_trimestre', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe com dados das DREs trimestrais, adicionada a coluna trimestre'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-dreitr-trimestre-df\"], dict_activities[\"act-adicionar-trimestre\"])            \n",
    "    \n",
    "    return dataframe_dre\n",
    "\n",
    "\n",
    "def standardization_account_value(dataframe_dre):\n",
    "\n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    # standardization account value\n",
    "    # divide by 1000 values when currency field is unidade\n",
    "    dataframe_dre['VL_CONTA'] = dataframe_dre.apply(lambda x: x.VL_CONTA/1000 if x.ESCALA_MOEDA == 'UNIDADE' \n",
    "                                         else x.VL_CONTA, axis = 1)\n",
    "    \n",
    "    # convert column currency data to valor mil\n",
    "    dataframe_dre['ESCALA_MOEDA'] = dataframe_dre.ESCALA_MOEDA.replace('UNIDADE', 'MIL')\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-padr-valor\"] = doc_prov.activity(\"ufrj:standardization_account_value\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-padr-valor\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-padr-valor\"],dict_entities[\"ent-dreitr-trimestre-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-obinvest-df\"] = doc_prov.entity('obinvest:df_obinvest', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataframe final com dados das DREs trimestrais'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-obinvest-df\"], dict_activities[\"act-padr-valor\"])            \n",
    "        \n",
    "    \n",
    "    return dataframe_dre\n",
    "\n",
    "def create_dataset_obinvest(df_obinvest):\n",
    "\n",
    "    #save execution start time\n",
    "    execStartTime = datetime.datetime.now()\n",
    "    \n",
    "    df_obinvest.to_csv('obinvest-dre-historico.csv', sep=';', encoding='\"ISO-8859-1', index=False)\n",
    "    \n",
    "    #create activity with final time execution\n",
    "    execEndTime = datetime.datetime.now()\n",
    "    dict_activities[\"act-cria-ds\"] = doc_prov.activity(\"ufrj:create_dataset_obinvest\", execStartTime, execEndTime)\n",
    "    \n",
    "    #associate activity with agent\n",
    "    doc_prov.wasAssociatedWith(dict_activities[\"act-cria-ds\"], dict_agents[\"ag-drecvm-ipynb\"])\n",
    "    \n",
    "    #associate activity with read datasets\n",
    "    doc_prov.used(dict_activities[\"act-cria-ds\"],dict_entities[\"ent-obinvest-df\"])\n",
    "    \n",
    "    #generate dataframe entity and associate with entity\n",
    "    dict_entities[\"ent-obinvest-ds\"] = doc_prov.entity('obinvest:ds_obinvest', {'prov:generatedAtTime': str(execEndTime), 'prov:label': 'Dataset final com historico de dados das DREs trimestrais', 'prov:type': 'void:Dataset'})\n",
    "    doc_prov.wasGeneratedBy(dict_entities[\"ent-obinvest-ds\"], dict_activities[\"act-cria-ds\"])       \n",
    "\n",
    "\n",
    "# processing data and create dataset obinvest\n",
    "def create_dataframe_obinvest():\n",
    "    \n",
    "    # load datasets \n",
    "    df_cia, df_itr, df_dfp = load_all_datasets()\n",
    "\n",
    "    #add year data\n",
    "    df_itr_ano, df_dfp_ano = adding_year_field_to_dre(df_itr, df_dfp)\n",
    "    \n",
    "    #sanitaze company data\n",
    "    df_cia_tratado = sanitaze_company_data(df_cia)\n",
    "    \n",
    "    #merge company info with itr, getting itr df sector - dfs cad_cia e itr\n",
    "    df_itr_sector = merge_dre_itr_sector(df_itr_ano, df_cia_tratado)\n",
    "\n",
    "    #filter quarters 1, 2 and 3 \n",
    "    df_trim123 = filter_quarters_123(df_itr_sector)\n",
    "\n",
    "    # filter 3 quarter cumulative\n",
    "    df_acm3 = filter_quarter3_cumulative(df_itr_sector)\n",
    "    \n",
    "    # slice dfp df\n",
    "    # filter last year values - df dfp\n",
    "    df_dfp_ultimo_exerc = filter_last_dfp_year(df_dfp_ano)\n",
    "    \n",
    "    # merge company and itr, using df dfp with sector - dfs cad_cia e dfp\n",
    "    df_dfp_sector = merge_dre_dfp_sector(df_dfp_ultimo_exerc, df_cia_tratado)\n",
    "    \n",
    "    # filter cumulated quarter 4\n",
    "    df_trim4 = filter_quarter_4(df_dfp_sector, df_acm3)\n",
    "    \n",
    "    # creating DF obinvest, concatenate dfs\n",
    "    df_obinvest_trim1234 = concatenate_quarters(df_trim123, df_trim4)\n",
    "    \n",
    "    # remove duplicated values\n",
    "    df_obinvest_tratado = remove_duplicate_records(df_obinvest_trim1234)\n",
    "    \n",
    "    #adding quater data\n",
    "    df_obinvest_campo_trimestre = adding_quarter_field(df_obinvest_tratado)\n",
    "    \n",
    "    #standardization account value\n",
    "    df_obinvest = standardization_account_value(df_obinvest_campo_trimestre)\n",
    "    \n",
    "    #create dataset obinvest\n",
    "    create_dataset_obinvest(df_obinvest)\n",
    "    \n",
    "    return df_obinvest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jj6eHx-iXV2O",
   "metadata": {
    "id": "jj6eHx-iXV2O"
   },
   "source": [
    "## **Provenance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfd234",
   "metadata": {
    "id": "d7dfd234"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, datetime\n",
    "from prov.model import ProvDocument, Namespace\n",
    "from prov.dot import prov_to_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "def generate_provenance_outputs():\n",
    "    entity = \"DRE-CVM-PROV\"\n",
    "    #Generating the outup - a  Provenance Graph\n",
    "    dot = prov_to_dot(doc_prov)\n",
    "    graph = entity+\".png\"\n",
    "    dot.write_png(graph)\n",
    "\n",
    "    #Generating the Serialization - Output XML\n",
    "    doc_prov.serialize(entity + \".xml\", format='xml') \n",
    "\n",
    "    #Generating the Serialization - Output Turtle\n",
    "    doc_prov.serialize(entity + \".ttl\", format='rdf', rdf_format='ttl')\n",
    "\n",
    "def adding_namespaces(document_prov):\n",
    "    # Declaring namespaces for various prefixes used in the excution of Randon Walk Experiment\n",
    "    document_prov.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')\n",
    "    document_prov.add_namespace('prov', 'http://www.w3.org/ns/prov#')\n",
    "    document_prov.add_namespace('void', 'http://vocab.deri.ie/void#')\n",
    "    document_prov.add_namespace('ufrj', 'https://www.ufrj.br')\n",
    "    document_prov.add_namespace('cvm', 'https://www.gov.br/cvm/pt-br')\n",
    "    document_prov.add_namespace('cvm-cademp', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/CAD/DADOS/')\n",
    "    document_prov.add_namespace('cvm-dre-itr', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    document_prov.add_namespace('cvm-dre-dfp', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/DFP/DADOS/')\n",
    "    document_prov.add_namespace('obinvest', 'https://www.obinvest.org')\n",
    "    return document_prov\n",
    "\n",
    "def create_agents(document_prov):\n",
    "    \n",
    "    #creating agents\n",
    "    dagnts={}\n",
    "    dagnts[\"ag-cvm\"] = document_prov.agent(\"cvm:CVM\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Comissão de Valores Mobiliários\"})\n",
    "    dagnts[\"ag-ufrj\"] = document_prov.agent(\"ufrj:UFRJ\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Universidade Federal do Rio de Janeiro\"})\n",
    "    dagnts[\"ag-ppgi\"] = document_prov.agent(\"ufrj:PPGI\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Programa de Pós Graduação em Informática\"})\n",
    "    dagnts[\"ag-greco\"] = document_prov.agent(\"ufrj:GRECO\", {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Greco Group\"})\n",
    "    dagnts[\"ag-author-gil\"] = document_prov.agent(\"ufrj:Gil\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Gilberto Gil Fidelis Gomes Passos\", \"foaf:mbox\":\"gilberto.passos@cefet-rj.br\"})\n",
    "    dagnts[\"ag-author-saulo\"] = document_prov.agent(\"ufrj:Saulo\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Saulo Andrade Almeida\", \"foaf:mbox\":\"sauloandrade@gmail.com\"})\n",
    "    dagnts[\"ag-author-valquire\"] = document_prov.agent(\"ufrj:Valquire\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Valquire da Silva de Jesus\", \"foaf:mbox\":\"valquire@ufrj.br\"})\n",
    "    dagnts[\"ag-author-sergio\"] = document_prov.agent(\"ufrj:Sergio\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Sergio Serra\", \"foaf:mbox\":\"serra@ppgi.ufrj.br\"})\n",
    "    dagnts[\"ag-author-jorge\"] = document_prov.agent(\"ufrj:Jorge\", {\"prov:type\":\"prov:Person\", \"foaf:name\":\"Jorge Zavaleta\", \"foaf:mbox\":\"zavaleta@pet-si.ufrrj.br\"})\n",
    "    dagnts[\"ag-drecvm-ipynb\"] = document_prov.agent(\"ufrj:drecvm.ipynb\", {\"prov:type\":\"prov:SoftwareAgent\", \"foaf:name\":\"drecvm.ipynb\", \"prov:label\":\"Notebook Python utilizado no trabalho\"})\n",
    "\n",
    "    return dagnts\n",
    "\n",
    "def associate_ufrj_agents(agents_dictionary):\n",
    "    agents_dictionary[\"ag-ppgi\"].actedOnBehalfOf(agents_dictionary[\"ag-ufrj\"])\n",
    "    agents_dictionary[\"ag-greco\"].actedOnBehalfOf(agents_dictionary[\"ag-ppgi\"])\n",
    "    agents_dictionary[\"ag-drecvm-ipynb\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-gil\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-saulo\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-valquire\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-sergio\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-author-jorge\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    agents_dictionary[\"ag-drecvm-ipynb\"].actedOnBehalfOf(agents_dictionary[\"ag-greco\"])\n",
    "    return agents_dictionary\n",
    "\n",
    "def create_initial_activities(document_prov):\n",
    "    #creating activities\n",
    "    dataDownloadDatasets = datetime.datetime.strptime('15/09/22', '%d/%m/%y')\n",
    "    \n",
    "    dativs={}\n",
    "    dativs[\"act-create-ds\"] = document_prov.activity(\"cvm:create-dataset\")\n",
    "    dativs[\"act-create-ds-obinvest\"] = document_prov.activity(\"ufrj:create-ds-obinvest\")\n",
    "    dativs[\"act-save-datasets\"] = document_prov.activity(\"ufrj:save-datasets\", dataDownloadDatasets, None)\n",
    "    return dativs\n",
    "    \n",
    "def create_initial_entities(document_prov):\n",
    "    #creating activities\n",
    "    dents={}\n",
    "    dents[\"ent-cademp-ds\"] = document_prov.entity('cvm-cademp:cad_cia_aberta.csv', {'prov:label': 'Dataset com dados cadastrais das empresas listadas na CVM', 'prov:type': 'void:Dataset'})\n",
    "    \n",
    "    #generate DRE data of ITR kind\n",
    "    dents[\"ent-dreitr\"] = document_prov.entity('cvm:dre-itr', {'prov:label': 'Documento que representa o conceito de DREs do tipo Trimestral', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2011-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2011.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2011', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2011-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2011.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2011', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2012-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2012.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2012', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2012-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2012.csv', {'prov:label': 'Dataset com dados de DRE trimestrais,  do anos de 2012', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2013-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2013.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2013', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2013-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2013.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2013', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2014-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2014.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2014', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2014-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2014.csv', {'prov:label': 'Dataset com dados de DRE trimestrais,  do anos de 2014', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2015-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2015.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2015', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2015-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2015.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2015', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2016-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2016.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2016', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2016-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2016.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2016', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2017-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2017.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2017', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2017-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2017.csv', {'prov:label': 'Dataset com dados de DRE trimestrais,  do anos de 2017', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2018-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2018.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2018', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2018-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2018.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2018', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2019-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2019.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2019', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2019-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2019.csv', {'prov:label': 'Dataset com dados de DRE trimestrais,  do anos de 2019', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2020-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2020.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2020', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2020-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2020.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2020', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dreitr2021-zip\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_2021.zip', {'prov:label': 'ZIP com Dataset com DRE trimestrais, do ano de 2021', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dreitr2021-ds\"] = document_prov.entity('cvm-dre-itr:itr_cia_aberta_DRE_con_2021.csv', {'prov:label': 'Dataset com dados de DRE trimestrais, do ano de 2021', 'prov:type': 'void:Dataset'})\n",
    "\n",
    "    #generate DRE data of DFP kind\n",
    "    dents[\"ent-dredfp\"] = document_prov.entity('cvm:dre-dfp', {'prov:label': 'Documento que representa o conceito de DREs do tipo Trimestral', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2011-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2011.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2011', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2011-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2011.csv', {'prov:label': 'Dataset com dados de DRE anual de 2011', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2012-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2012.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2012', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2012-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2012.csv', {'prov:label': 'Dataset com dados de DRE anual,  do anos de 2012', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2013-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2013.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2013', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2013-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2013.csv', {'prov:label': 'Dataset com dados de DRE anual de 2013', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2014-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2014.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2014', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2014-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2014.csv', {'prov:label': 'Dataset com dados de DRE anual,  do anos de 2014', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2015-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2015.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2015', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2015-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2015.csv', {'prov:label': 'Dataset com dados de DRE anual de 2015', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2016-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2016.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2016', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2016-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2016.csv', {'prov:label': 'Dataset com dados de DRE anual de 2016', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2017-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2017.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2017', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2017-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2017.csv', {'prov:label': 'Dataset com dados de DRE anual,  do anos de 2017', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2018-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2018.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2018', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2018-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2018.csv', {'prov:label': 'Dataset com dados de DRE anual de 2018', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2019-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2019.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2019', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2019-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2019.csv', {'prov:label': 'Dataset com dados de DRE anual de 2019', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2020-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2020.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2020', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2020-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2020.csv', {'prov:label': 'Dataset com dados de DRE anual de 2020', 'prov:type': 'void:Dataset'})\n",
    "    dents[\"ent-dredfp2021-zip\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_2021.zip', {'prov:label': 'ZIP com Dataset com DRE anual de 2021', 'prov:type': 'foaf:Document'})\n",
    "    dents[\"ent-dredfp2021-ds\"] = document_prov.entity('cvm-dre-dfp:dfp_cia_aberta_DRE_con_2021.csv', {'prov:label': 'Dataset com dados de DRE anual de 2021', 'prov:type': 'void:Dataset'})\n",
    "    \n",
    "    dents[\"ent-git-obinvest\"] = document_prov.entity('obinvest:github-drecvm', {'prov:label': 'Repositorio DRECVM da OBInvest', 'prov:type': 'prov:Collection'})\n",
    "    \n",
    "    return dents\n",
    "    \n",
    "def initial_association_agents_activities_entities(document_prov, dictionary_agents, \n",
    "                                                   dictionary_activities, dictionary_entities):\n",
    "    \n",
    "    #Associate activity of generate dataset with CVM agent\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds\"], \n",
    "                                     dictionary_agents[\"ag-cvm\"])\n",
    "    \n",
    "    #Associating datasets with activities of generate CVM datasets\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-cademp-ds\"], dictionary_activities[\"act-create-ds\"])\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-dreitr\"], dictionary_activities[\"act-create-ds\"])    \n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-dredfp\"], dictionary_activities[\"act-create-ds\"])\n",
    "    \n",
    "    #Associating ZIPs, DREs ITR e DFP with entities of generic datasets\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2011-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2012-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2013-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2014-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2015-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2016-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2017-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2018-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2019-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2020-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2021-zip\"], dictionary_entities[\"ent-dreitr\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2011-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2012-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2013-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2014-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2015-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2016-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2017-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2018-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2019-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2020-zip\"], dictionary_entities[\"ent-dredfp\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2021-zip\"], dictionary_entities[\"ent-dredfp\"])  \n",
    "    \n",
    "    #Associating ZIPs, DREs ITR e DFP with CSVs\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2011-ds\"], dictionary_entities[\"ent-dreitr2011-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2012-ds\"], dictionary_entities[\"ent-dreitr2012-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2013-ds\"], dictionary_entities[\"ent-dreitr2013-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2014-ds\"], dictionary_entities[\"ent-dreitr2014-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2015-ds\"], dictionary_entities[\"ent-dreitr2015-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2016-ds\"], dictionary_entities[\"ent-dreitr2016-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2017-ds\"], dictionary_entities[\"ent-dreitr2017-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2018-ds\"], dictionary_entities[\"ent-dreitr2018-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2019-ds\"], dictionary_entities[\"ent-dreitr2019-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2020-ds\"], dictionary_entities[\"ent-dreitr2020-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2021-ds\"], dictionary_entities[\"ent-dreitr2021-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2011-ds\"], dictionary_entities[\"ent-dredfp2011-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2012-ds\"], dictionary_entities[\"ent-dredfp2012-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2013-ds\"], dictionary_entities[\"ent-dredfp2013-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2014-ds\"], dictionary_entities[\"ent-dredfp2014-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2015-ds\"], dictionary_entities[\"ent-dredfp2015-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2016-ds\"], dictionary_entities[\"ent-dredfp2016-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2017-ds\"], dictionary_entities[\"ent-dredfp2017-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2018-ds\"], dictionary_entities[\"ent-dredfp2018-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2019-ds\"], dictionary_entities[\"ent-dredfp2019-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2020-ds\"], dictionary_entities[\"ent-dredfp2020-zip\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2021-ds\"], dictionary_entities[\"ent-dredfp2021-zip\"])    \n",
    "    \n",
    "    #associate activity of obinvest, with greco group\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds-obinvest\"], dictionary_agents[\"ag-greco\"])   \n",
    "\n",
    "    #associate notebook agent with obinvest dataset\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-create-ds-obinvest\"], dictionary_agents[\"ag-drecvm-ipynb\"])    \n",
    "    \n",
    "    #associate activities dataset storing with greco group\n",
    "    document_prov.wasAssociatedWith(dictionary_activities[\"act-save-datasets\"], dictionary_agents[\"ag-greco\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-cademp-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2011-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2012-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2013-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2014-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2015-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2016-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2017-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2018-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2019-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2020-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dreitr2021-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2011-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2012-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2013-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2014-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2015-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2016-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2017-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2018-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2019-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2020-ds\"])\n",
    "    document_prov.used(dictionary_activities[\"act-save-datasets\"],dictionary_entities[\"ent-dredfp2021-ds\"])\n",
    "    \n",
    "    #associate obinvest github repository with store datasets activity\n",
    "    document_prov.wasGeneratedBy(dictionary_entities[\"ent-git-obinvest\"], dictionary_activities[\"act-save-datasets\"])\n",
    "    \n",
    "    #detailing csvs in github\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-cademp-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2011-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2012-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2013-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2014-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2015-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2016-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2017-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2018-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2019-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2020-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dreitr2021-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2011-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2012-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2013-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2014-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2015-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2016-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2017-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2018-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2019-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2020-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    document_prov.wasDerivedFrom(dictionary_entities[\"ent-dredfp2021-ds\"], dictionary_entities[\"ent-git-obinvest\"])\n",
    "    \n",
    "def initProvenance():\n",
    "    # Creating an empty provenance document\n",
    "    doc_prov = ProvDocument()\n",
    "\n",
    "    #creating namespacing of provenabce document\n",
    "    doc_prov = adding_namespaces(doc_prov)\n",
    "    \n",
    "    #create agents\n",
    "    agents_dict = create_agents(doc_prov)\n",
    "    \n",
    "    #creating agents hierarchy\n",
    "    agents_dict = associate_ufrj_agents(agents_dict)\n",
    "    \n",
    "    #create initial activities\n",
    "    activities_dict = create_initial_activities(doc_prov)\n",
    "    \n",
    "    #create initial entities\n",
    "    entities_dict = create_initial_entities(doc_prov)\n",
    "    \n",
    "    #initial provenance associations\n",
    "    initial_association_agents_activities_entities(doc_prov, agents_dict, activities_dict, entities_dict)\n",
    "    \n",
    "    #return provenance objects\n",
    "    return doc_prov, agents_dict, activities_dict, entities_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ds8Kte_9X8Sm",
   "metadata": {
    "id": "Ds8Kte_9X8Sm"
   },
   "source": [
    "## **Example of Data Analytic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N5hJH1HA69cq",
   "metadata": {
    "id": "N5hJH1HA69cq"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def sector_margin_analytic_example(dataFrameObinvest):\n",
    "\n",
    "  # filter df obinvest of accounts 3.01\n",
    "  df_conta_301 = dataFrameObinvest.query('CD_CONTA == \"3.01\"')\n",
    "\n",
    "  # filter df obinvest of accounts 3.09\n",
    "  df_conta_309 = dataFrameObinvest.query('CD_CONTA == \"3.09\"')\n",
    " \n",
    "  # grouping by account, sector, year and quarter\n",
    "  vetor_301 = df_conta_301.groupby(['SETOR_ATIV', 'DT_REFER'])['VL_CONTA'].sum()\n",
    "  vetor_309 = df_conta_309.groupby(['SETOR_ATIV', 'DT_REFER'])['VL_CONTA'].sum()\n",
    "\n",
    "  df_margem_setor = pd.DataFrame(vetor_301)\n",
    "  df_margem_setor = df_margem_setor.rename(columns = {'VL_CONTA':'SOMA_CONTA_3_01'})\n",
    "  df_margem_setor['SOMA_CONTA_3_09'] = vetor_309.values\n",
    "  df_margem_setor['MARGEM_SETOR'] = df_margem_setor.apply(lambda x: 0 if x.SOMA_CONTA_3_01 == 0 else (x.SOMA_CONTA_3_09/x.SOMA_CONTA_3_01) * 100,  axis = 1)\n",
    "    \n",
    "  data_ref=[]\n",
    "  for sub_lista in df_margem_setor.index:\n",
    "    data_ref.append(sub_lista[1])  # select quarter\n",
    "\n",
    "  setores=[]\n",
    "  for sub_lista in df_margem_setor.index:\n",
    "    setores.append(sub_lista[0])  # select quarter\n",
    "\n",
    "  df_margem_setor['DT_REFER'] = data_ref\n",
    "  df_margem_setor['SETOR'] = setores\n",
    "\n",
    "  query =  ' SETOR == \"Energia Elétrica\" | '\n",
    "  query += ' SETOR == \"Bancos\" | '\n",
    "  query += ' SETOR == \"Serviços Transporte e Logística\" | '\n",
    "  query += ' SETOR == \"Comércio (Atacado e Varejo)\" | '\n",
    "  query += ' SETOR == \"Educação\" '\n",
    "\n",
    "  df_margem_setor = df_margem_setor.query(query)\n",
    "\n",
    "  fig = px.line(df_margem_setor, x=\"DT_REFER\", y=df_margem_setor['MARGEM_SETOR'],\n",
    "              title='Margem Setor', color='SETOR', markers=True, symbol=\"SETOR\")\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c2191",
   "metadata": {
    "id": "1a8c2191"
   },
   "source": [
    "## **Main Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b83e9",
   "metadata": {
    "id": "d04b83e9"
   },
   "outputs": [],
   "source": [
    "def executeNotebook():\n",
    "    df_obinvest = create_dataframe_obinvest()\n",
    "    plotSectorMargin = sector_margin_analytic_example(df_obinvest)\n",
    "    generate_provenance_outputs()\n",
    "    return plotSectorMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb0ff2",
   "metadata": {
    "id": "42cb0ff2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#provenance objects were declare in global scope, just to avoid pass as parameters to all methods\n",
    "doc_prov, dict_agents , dict_activities, dict_entities = initProvenance()\n",
    "\n",
    "def main():\n",
    "    if(verify_libs_environment_versions()):\n",
    "        return executeNotebook()\n",
    "    else:\n",
    "        print('Notbook was not executed. Verify all environment and libs versions!')\n",
    "\n",
    "plotSectorMargin = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSectorMargin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"DRE-CVM-PROV.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "drecvm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
