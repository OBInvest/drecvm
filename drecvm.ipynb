{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4851321",
   "metadata": {
    "id": "c4851321"
   },
   "source": [
    "![PPGI_UFRJ](https://github.com/zavaleta/Fundamentos_DS/blob/main/imagens/ppgi-ufrj.png?raw=1)\n",
    "# **Fundamentos de Ciência de Dados**\n",
    "\n",
    "> Trabalho Final - 2º Período de 2022\n",
    "\n",
    "### **Disponibilizando Dados sobre Resultados Financeiros de Cias Abertas Enriquecidos com Proveniência para a [OBInvest](https://obinvest.org/)**\n",
    "\n",
    "---\n",
    "\n",
    "**Alunos:** Gilberto Gil | Saulo Andrade Almeida | Valquire Jesus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tZBqeLEhT_H6",
   "metadata": {
    "id": "tZBqeLEhT_H6"
   },
   "source": [
    "## **FAIRificação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4oia7HvEySA",
   "metadata": {
    "id": "z4oia7HvEySA"
   },
   "outputs": [],
   "source": [
    "#checking version machine architecture, OS, python and all libs used in this notebook\n",
    "import platform as platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import conda\n",
    "import pydot\n",
    "import prov\n",
    "\n",
    "def checkingEnvironmentVersions(details=False):\n",
    "\n",
    "    #definnig version of python and all libs used\n",
    "    HOST_MACHINE_ARCHTECTURE_EXPECTED = 'x86_64'\n",
    "    HOST_MACHINE_OS_EXPECTED = 'Linux'\n",
    "    CONDA_VERSION_EXPECTED = '4.14.0'\n",
    "    CONDA_DEFAULT_ENV_EXPECTED = 'drecvmenv'\n",
    "    PYTHON_VERSION_EXPECTED = '3.9.12'\n",
    "    NUMPY_LIB_VERSION_EXPECTED = '1.21.5'\n",
    "    PANDAS_LIB_VERSION_EXPECTED = '1.4.2'\n",
    "    PYDOT_LIB_VERSION_EXPECTED = '1.4.2'\n",
    "    PROV_LIB_VERSION_EXPECTED = '2.0.0'\n",
    "    \n",
    "\n",
    "    if details: \n",
    "        print('Host Machine Architecture:', platform.machine())\n",
    "        print('Host Machine OS:', platform.system())\n",
    "        print('Conda Version:', conda.__version__)\n",
    "        print('Conda default env:', os.environ['CONDA_DEFAULT_ENV'])\n",
    "        print('Python Version:', platform.python_version())\n",
    "        print('NumPy Lib Version:', np.__version__)\n",
    "        print('Pandas Lib Version:', pd.__version__)\n",
    "        print('PyDot Lib Version:', pydot.__version__)\n",
    "        print('Prov Lib Version:', prov.__version__)\n",
    "        \n",
    "    #checking versions\n",
    "    try:\n",
    "        #checking Machine Architecute expected\n",
    "        assert platform.machine() == HOST_MACHINE_ARCHTECTURE_EXPECTED\n",
    "\n",
    "        #checking OS expected\n",
    "        assert platform.system() == HOST_MACHINE_OS_EXPECTED\n",
    "        \n",
    "        #checking conda version\n",
    "        assert conda.__version__ == CONDA_VERSION_EXPECTED\n",
    "        \n",
    "        #checking conda default environment\n",
    "        assert os.environ['CONDA_DEFAULT_ENV'] == CONDA_DEFAULT_ENV_EXPECTED    \n",
    "\n",
    "        #checking python version\n",
    "        assert platform.python_version() == PYTHON_VERSION_EXPECTED\n",
    "\n",
    "        #checking numpy lib version\n",
    "        assert np.__version__ == NUMPY_LIB_VERSION_EXPECTED  \n",
    "\n",
    "        #checking Pandas lib version\n",
    "        assert pd.__version__ == PANDAS_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking pydot version\n",
    "        assert pydot.__version__ == PYDOT_LIB_VERSION_EXPECTED\n",
    "        \n",
    "        #checking prov version\n",
    "        assert prov.__version__ == PROV_LIB_VERSION_EXPECTED\n",
    "    except:\n",
    "        #if any assert fail, or something else get wrong during verification\n",
    "        if details: print('Something is wrong!')\n",
    "        return False\n",
    "    else:\n",
    "        #if pass all asserts\n",
    "        if details: print('All versions are correct!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rgNNU7YaUVi1",
   "metadata": {
    "id": "rgNNU7YaUVi1"
   },
   "source": [
    "## **Pré-processamento de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9be604",
   "metadata": {
    "id": "df9be604"
   },
   "outputs": [],
   "source": [
    "#Utilizado ambiente python 3.9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def loadCsv(path, file):\n",
    "  if path == 'data/cad-emp/':  # condição para fazer leitura do csv cadastro de companias\n",
    "    return pd.read_csv(path+file, sep=';', header=0, encoding=\"ISO-8859-1\")\n",
    "  return pd.read_csv(path+file, sep=';', header=0, encoding=\"ISO-8859-1\", parse_dates=['DT_REFER', 'DT_INI_EXERC', \n",
    "                                                                                       'DT_FIM_EXERC'])\n",
    "\n",
    "def loadCompanyInfo():\n",
    "    return loadCsv(\"data/cad-emp/\", \"cad_cia_aberta.csv\")\n",
    "\n",
    "def allHistoricalYears():\n",
    "    return [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "def loadDreItr(years):\n",
    "    tempDF = pd.DataFrame() \n",
    "    for year in years:\n",
    "        tempDF = pd.concat([tempDF, loadCsv(\"data/dre-itr/\",\"itr_cia_aberta_DRE_con_{0}.csv\".format(year))], \n",
    "                           ignore_index=True)\n",
    "    return tempDF\n",
    "\n",
    "def loadDreDfp(years):\n",
    "    tempDF = pd.DataFrame() \n",
    "    for year in years:\n",
    "        tempDF = pd.concat([tempDF, loadCsv(\"data/dre-dfp/\",f'dfp_cia_aberta_DRE_con_{year}.csv')], \n",
    "                           ignore_index=True)\n",
    "    return tempDF\n",
    "\n",
    "def loadAllDreItr():\n",
    "    return loadDreItr(allHistoricalYears())\n",
    "\n",
    "def loadAllDreDfp():\n",
    "    return loadDreDfp(allHistoricalYears())\n",
    "\n",
    "def carregar_datasets():\n",
    "    companyInfoDF = loadCompanyInfo()\n",
    "    dreItrDF = loadAllDreItr()\n",
    "    dreDfpDF = loadAllDreDfp()\n",
    "    return companyInfoDF, dreItrDF, dreDfpDF\n",
    "\n",
    "def trata_dados_companhias(dataframe_cia):\n",
    "    # TRATAMENTO DO DF CAD_CIA\n",
    "    # filtrar as empresas com cadastro ativo - df cad_cia\n",
    "    dataframe_cia = dataframe_cia[dataframe_cia['SIT'] == 'ATIVO']\n",
    "    # deletar colunas desnecessárias\n",
    "    dataframe_cia = dataframe_cia.drop(['DENOM_SOCIAL', 'DENOM_COMERC', 'DT_REG', 'DT_CONST', 'DT_CANCEL', 'MOTIVO_CANCEL', 'SIT', \n",
    "                   'DT_INI_SIT', 'TP_MERC', 'CATEG_REG', 'DT_INI_CATEG', 'SIT_EMISSOR', 'DT_INI_SIT_EMISSOR', \n",
    "                   'CONTROLE_ACIONARIO', 'TP_ENDER', 'LOGRADOURO', 'COMPL', 'BAIRRO', 'MUN', 'UF', 'PAIS', \n",
    "                   'CEP', 'DDD_TEL', 'TEL', 'DDD_FAX', 'FAX', 'EMAIL', 'TP_RESP', 'RESP', 'DT_INI_RESP', \n",
    "                   'LOGRADOURO_RESP', 'COMPL_RESP', 'BAIRRO_RESP', 'MUN_RESP', 'UF_RESP', 'PAIS_RESP', \n",
    "                   'CEP_RESP', 'DDD_TEL_RESP', 'TEL_RESP', 'DDD_FAX_RESP', 'FAX_RESP', 'EMAIL_RESP', \n",
    "                   'CNPJ_AUDITOR', 'AUDITOR'], axis=1)\n",
    "    \n",
    "    # deletar os registros duplicados, que possuem mesmos cnpj e códigos cvm\n",
    "    dataframe_cia = dataframe_cia.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM'], keep = 'last')\n",
    "    \n",
    "    #TODO:Gerar proveniencia do tratamento de companhias\n",
    "    return dataframe_cia\n",
    "\n",
    "def adiciona_ano(dataframe_dre):\n",
    "    ano = []\n",
    "    \n",
    "    #adicionando as informacoes da coluna de Ano\n",
    "    for i in dataframe_dre.itertuples():\n",
    "        ano.append(i.DT_REFER.year)\n",
    "    \n",
    "    dataframe_dre['ANO'] = ano\n",
    "    \n",
    "    return dataframe_dre\n",
    "\n",
    "def adiciona_trimestre(dataframe_dre):\n",
    "    trimestre =[]\n",
    "    \n",
    "    #adicionando as informacoes da coluna de trimestre\n",
    "    for i in dataframe_dre.itertuples():\n",
    "      if i.DT_REFER.month == 3:\n",
    "        trimestre.append(1)\n",
    "      elif i.DT_REFER.month == 6:\n",
    "        trimestre.append(2)\n",
    "      elif i.DT_REFER.month == 9:\n",
    "        trimestre.append(3)\n",
    "      else:\n",
    "        trimestre.append(4)\n",
    "    \n",
    "    dataframe_dre['TRIMESTRE'] = trimestre\n",
    "    \n",
    "    return dataframe_dre\n",
    "\n",
    "def merge_dre_setor(dataframe_dre, dataframe_cia):\n",
    "    return pd.merge(dataframe_dre, dataframe_cia, how = 'inner', on = ['CNPJ_CIA', 'CD_CVM']).reset_index(drop=True)\n",
    "    \n",
    "def filtrarUltimoExerc(dre):\n",
    "    # Descartando resultados do ano anterior e mantendo apenas o último valor \n",
    "    return dre[dre['ORDEM_EXERC'] == 'ÚLTIMO']\n",
    "    \n",
    "def obter_trimestres_123(dataframe_itr):\n",
    "    # FATIAMENTO DO DF ITR\n",
    "    dataframe_itr = filtrarUltimoExerc(dataframe_itr)\n",
    "    # OBTENÇÃO DO DF TRIMESTRES 1, 2 E 3\n",
    "    # criar o df com informações dos trimestres 1 (1 a 3 mês), 2 (4 a 6 mês) e 3 (6 a 9 mês) - df trim123\n",
    "    return dataframe_itr.loc[lambda dataframe_itr: (dataframe_itr.DT_REFER.dt.month == 3) | \n",
    "                            ((dataframe_itr.DT_REFER.dt.month == 6) & (dataframe_itr.DT_INI_EXERC.dt.month > 3)) | \n",
    "                            ((dataframe_itr.DT_REFER.dt.month == 9) & (dataframe_itr.DT_INI_EXERC.dt.month > 6))]\n",
    "\n",
    "def obter_acumulado_trim3(dataframe_itr):\n",
    "    # criar o df com informações acumuladas até o trimestre 3, 01/07/ANO a 30/09/ANO - df_acm3\n",
    "    return dataframe_itr.loc[lambda dataframe_itr: ((dataframe_itr.DT_REFER.dt.month == 9) & \n",
    "                                                   (dataframe_itr.DT_INI_EXERC.dt.month <= 6))]\n",
    "\n",
    "def obter_trimestre_4(dataframe_dfp, dataframe_acm3):\n",
    "    # filtrar os informes acumulados no trimestre 4, 01/10/ANO a 31/12/ANO - df acm4\n",
    "    df_acm4 = dataframe_dfp.loc[lambda df_dfp_setor: (dataframe_dfp.DT_REFER.dt.month == 12)]\n",
    "    # fazer o merge entre df acumulado 4 e df acumulado 3, mantendo o df acumulado 4 - df trim4\n",
    "    df_trim4 = pd.merge(df_acm4, dataframe_acm3, how='left', on=['CD_CVM', 'CD_CONTA', 'ANO'], suffixes=['_acm4','_acm3'])\n",
    "    # preencher valores VL_CONTA ausentes com 0, informes que não foram enviados por Cias até o trimestre 3\n",
    "    df_trim4.VL_CONTA_acm3.fillna(value=0, inplace=True)\n",
    "    # calcular o valor do trimestre 4, fazendo a subtração entre acumulado anual e o acumulado do trimestre 3\n",
    "    df_trim4['RESULTADO'] = df_trim4['VL_CONTA_acm4'] - df_trim4['VL_CONTA_acm3']\n",
    "    # deletar colunas desnecessárias\n",
    "    df_trim4 = df_trim4.drop(['VL_CONTA_acm4','CNPJ_CIA_acm3', 'DT_REFER_acm3', 'VERSAO_acm3', 'DENOM_CIA_acm3', 'GRUPO_DFP_acm3', \n",
    "                 'MOEDA_acm3', 'ESCALA_MOEDA_acm3', 'ORDEM_EXERC_acm3', 'DT_INI_EXERC_acm3', 'DT_FIM_EXERC_acm3', \n",
    "                 'DS_CONTA_acm3', 'VL_CONTA_acm3', 'ST_CONTA_FIXA_acm3','SETOR_ATIV_acm3'], axis=1)\n",
    "    # renomear as colunas para a concatenação com o df trim123\n",
    "    return df_trim4.rename(columns = {'CNPJ_CIA_acm4':'CNPJ_CIA', 'DT_REFER_acm4':'DT_REFER', 'VERSAO_acm4':'VERSAO', \n",
    "                             'DENOM_CIA_acm4':'DENOM_CIA', 'GRUPO_DFP_acm4':'GRUPO_DFP', 'MOEDA_acm4':'MOEDA', \n",
    "                             'ESCALA_MOEDA_acm4':'ESCALA_MOEDA', 'ORDEM_EXERC_acm4':'ORDEM_EXERC', \n",
    "                             'DT_INI_EXERC_acm4':'DT_INI_EXERC', 'DT_FIM_EXERC_acm4':'DT_FIM_EXERC', \n",
    "                             'DS_CONTA_acm4':'DS_CONTA', 'ST_CONTA_FIXA_acm4':'ST_CONTA_FIXA', \n",
    "                             'SETOR_ATIV_acm4':'SETOR_ATIV', 'RESULTADO':'VL_CONTA'})\n",
    "\n",
    "def padronizacao_valor_conta(dataframe_dre):\n",
    "    # PADRONIZAÇÃO DA COLUNA VL_CONTA\n",
    "    # dividir por 1000 os valores em que a escala moeda é unidade\n",
    "    dataframe_dre['VL_CONTA'] = dataframe_dre.apply(lambda x: x.VL_CONTA/1000 if x.ESCALA_MOEDA == 'UNIDADE' \n",
    "                                         else x.VL_CONTA, axis = 1)\n",
    "    \n",
    "    # renomear os dados da coluna escala moeda para o valor mil\n",
    "    dataframe_dre['ESCALA_MOEDA'] = dataframe_dre.ESCALA_MOEDA.replace('UNIDADE', 'MIL')\n",
    "    return dataframe_dre\n",
    "\n",
    "\n",
    "# faz a limpeza dos datasets cad_cia, dre_itr e dre_dfp e retorna o dataset obinvest\n",
    "def criar_dataset_obinvest():\n",
    "    # carrega os datasets \n",
    "    df_cia, df_itr, df_dfp = carregar_datasets()\n",
    "\n",
    "    #adicionar dados de Ano e Trimestres\n",
    "    df_itr = adiciona_ano(df_itr)\n",
    "    df_dfp = adiciona_ano(df_dfp)\n",
    "    \n",
    "    #Tratando dados de companhia\n",
    "    df_cia = trata_dados_companhias(df_cia)\n",
    "    \n",
    "    # fazer merge entre cadastro e informe itr, obtendo o df itr com setor - dfs cad_cia e itr\n",
    "    df_itr_setor = merge_dre_setor(df_itr, df_cia)\n",
    "\n",
    "    #Filtrando dados dos 3 primeiros trimestres e adicionando os campos de ano e \n",
    "    df_trim123 = obter_trimestres_123(df_itr_setor)\n",
    "\n",
    "    # OBTENÇÃO DO DF ACUMULADO TRIMESTRE 3\n",
    "    df_acm3 = obter_acumulado_trim3(df_itr_setor)\n",
    "    \n",
    "    #\n",
    "    # FATIAMENTO DO DF DFP\n",
    "    # filtrar últimos informes anuais - df dfp\n",
    "    df_dfp = filtrarUltimoExerc(df_dfp)\n",
    "    # fazer merge entre cadastro e informe itr, obtendo o df dfp com setor - dfs cad_cia e dfp\n",
    "    df_dfp_setor = merge_dre_setor(df_dfp, df_cia)\n",
    "    \n",
    "    # OBTENÇÃO DO DF ACUMULADO TRIMESTRE 4\n",
    "    df_trim4 = obter_trimestre_4(df_dfp_setor, df_acm3)\n",
    "    \n",
    "    # CRIAÇÃO DO DF OBINVEST\n",
    "    # criar o df obinvest, concatenando os informes referentes aos 4 trimestres\n",
    "    df_obinvest = pd.concat([df_trim123, df_trim4])\n",
    "    \n",
    "    # comparar registros antes e depois\n",
    "    print('Antes: Linhas = {0} | Colunas = {1}'.format(df_obinvest.shape[0], df_obinvest.shape[1]))\n",
    "    \n",
    "    # deletar os registros duplicados\n",
    "    df_obinvest.drop_duplicates(subset = ['CNPJ_CIA', 'CD_CVM', 'CD_CONTA', 'DT_INI_EXERC', 'DT_FIM_EXERC', 'ANO'], \n",
    "                              keep = 'last', inplace=True)\n",
    "    \n",
    "    print('Depois: Linhas = {0} | Colunas = {1}'.format(df_obinvest.shape[0], df_obinvest.shape[1]))\n",
    "    \n",
    "    #Adicionar dado de trimestre\n",
    "    df_obinvest = adiciona_trimestre(df_obinvest)\n",
    "    \n",
    "    #padronizacao valores contas\n",
    "    return padronizacao_valor_conta(df_obinvest)\n",
    "    #return df_obinvest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jj6eHx-iXV2O",
   "metadata": {
    "id": "jj6eHx-iXV2O"
   },
   "source": [
    "## **Proveniência de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfd234",
   "metadata": {
    "id": "d7dfd234"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, datetime\n",
    "from prov.model import ProvDocument, Namespace\n",
    "from prov.dot import prov_to_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "def inicializaProveniencia():\n",
    "    # Creating an empty provenance document\n",
    "    docProv = ProvDocument()\n",
    "\n",
    "    # Declaring namespaces for various prefixes used in the excution of Randon Walk Experiment\n",
    "    docProv.add_namespace('foaf', 'http://xmlns.com/foaf/0.1/')\n",
    "    docProv.add_namespace('prov', 'http://www.w3.org/ns/prov#')\n",
    "    docProv.add_namespace('void', 'http://vocab.deri.ie/void#')\n",
    "    docProv.add_namespace('cvm', 'https://www.gov.br/cvm/pt-br')\n",
    "    docProv.add_namespace('cvm-cademp', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/CAD/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2011', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2012', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2013', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2014', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2015', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2016', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2017', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2018', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2019', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2020', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-itr-2021', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/')\n",
    "    docProv.add_namespace('cvm-dre-dfp-2010', 'https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/DFP/DADOS/')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Creating all entity\n",
    "    entDsCadEmp = docProv.entity('cvm-cademp:cad_cia_aberta.csv', {'prov:label': 'Dataset com dados da empresas listadas na CVM', 'prov:type': 'void:Dataset'})\n",
    "    \n",
    "    entDreItr = docProv.entity('cvm:dre-trimestral', {'prov:label': 'Documrnto que representa o conceito de DREs do tipo Trimestral', 'prov:type': 'foaf:Document'})\n",
    "    entDsDreItr2011 = docProv.entity(\"cvm-dre-itr-2011:itr_cia_aberta_2011.zip\", {'prov:label': 'Dataset com DRE trimestrais, do ano de 2011', 'prov:type': 'void:Dataset'})\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2011:itr_cia_aberta_2011.zip', 'cvm:dre-trimestral')\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2011:itr_cia_aberta_DRE_con_2011.csv', 'cvm-dre-itr-2011:itr_cia_aberta_2011.zip')\n",
    "    entDsDreItr2012 = docProv.entity(\"cvm-dre-itr-2012:itr_cia_aberta_2012.zip\", {'prov:label': 'Dataset com DRE trimestrais, do ano de 2012', 'prov:type': 'void:Dataset'})\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2012:itr_cia_aberta_2012.zip', 'cvm:dre-trimestral')\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2012:itr_cia_aberta_DRE_con_2012.csv', 'cvm-dre-itr-2012:itr_cia_aberta_2012.zip')\n",
    "    entDsDreItr2013 = docProv.entity(\"cvm-dre-itr-2013:itr_cia_aberta_2013.zip\", {'prov:label': 'Dataset com DRE trimestrais, do ano de 2013', 'prov:type': 'void:Dataset'})\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2013:itr_cia_aberta_2013.zip', 'cvm:dre-trimestral')\n",
    "    docProv.wasDerivedFrom('cvm-dre-itr-2013:itr_cia_aberta_DRE_con_2013.csv', 'cvm-dre-itr-2013:itr_cia_aberta_2013.zip')\n",
    "\n",
    "    \n",
    "    \n",
    "    entDreDfp = docProv.entity('cvm:dre-anual', {'prov:label': 'Documento que representa o conceito de DREs do tipo Anual', 'prov:type': 'foaf:Document'})\n",
    "    entDsDreDfp2010 = docProv.entity(\"cvm-dre-dfp-2010:dfp_cia_aberta_2010.zip\", {'prov:label': 'Dataset com DRE anual, do ano de 2010', 'prov:type': 'void:Dataset'})\n",
    "    docProv.wasDerivedFrom('cvm-dre-dfp-2010:dfp_cia_aberta_2010.zip', 'cvm:dre-anual')\n",
    "    docProv.wasDerivedFrom('cvm-dre-dfp-2010:dfp_cia_aberta_DRE_con_2010.csv', 'cvm-dre-dfp-2010:dfp_cia_aberta_2010.zip')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Creating all Agents  \n",
    "    agntCvm = docProv.agent(\"cvm:CVM\", \n",
    "                            {\"prov:type\":\"prov:Organization\", \"foaf:name\":\"Comissão de Valores Mobiliários\"})\n",
    "    \n",
    "    # create activity of dataset creations\n",
    "    actvCreateDs = docProv.activity(\"cvm:create-dataset\")    \n",
    "    \n",
    "    # Generation\n",
    "    docProv.wasGeneratedBy(entDsCadEmp, actvCreateDs)\n",
    "    docProv.wasGeneratedBy(entDreItr, actvCreateDs)\n",
    "    docProv.wasGeneratedBy(entDreDfp, actvCreateDs)\n",
    "    \n",
    "    docProv.wasAssociatedWith(actvCreateDs, agntCvm)\n",
    "\n",
    "    ### END - Registering Retrospective Provenance \n",
    "\n",
    "    ### Optional outputs ####\n",
    "    \n",
    "    entity = \"DRE-CVM-PROV\"\n",
    "    #Generating the outup - a  Provenance Graph\n",
    "    dot = prov_to_dot(docProv)\n",
    "    graph = entity+\".png\"\n",
    "    dot.write_png(graph)\n",
    "\n",
    "    #Generating the Serialization - Output XML\n",
    "    docProv.serialize(entity + \".xml\", format='xml') \n",
    "\n",
    "    #Generating the Serialization - Output Turtle\n",
    "    docProv.serialize(entity + \".ttl\", format='rdf', rdf_format='ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ds8Kte_9X8Sm",
   "metadata": {
    "id": "Ds8Kte_9X8Sm"
   },
   "source": [
    "## **Análise de Dados**\n",
    "### **Análise Inicial dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yWzWQts26z5m",
   "metadata": {
    "id": "yWzWQts26z5m"
   },
   "outputs": [],
   "source": [
    "def analiseInicialDataset(dataframe_obinvest):\n",
    "    print(dataframe_obinvest.info())\n",
    "    print(dataframe_obinvest.shape)\n",
    "    print(dataframe_obinvest.isnull().sum())\n",
    "    print(dataframe_obinvest.describe())\n",
    "    print(dataframe_obinvest.columns)\n",
    "    print(dataframe_obinvest.DT_REFER.value_counts())\n",
    "    print(dataframe_obinvest.ESCALA_MOEDA.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebdfbe",
   "metadata": {},
   "source": [
    "### **Análise Estatística dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N5hJH1HA69cq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5hJH1HA69cq",
    "outputId": "0c182f7d-b81b-4a4b-e5ae-388a425433f9"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "def analiseEstatisticaDataset(dataFrameObinvest):\n",
    "    print('Rodando experimento de dataset estatisticos')\n",
    "    sns.displot(dataFrameObinvest['VL_CONTA'], bins=30)\n",
    "    fig1 = px.scatter(dataFrameObinvest, x = dataFrameObinvest.CD_CONTA.index, y = dataFrameObinvest.ANO, \n",
    "                      color=dataFrameObinvest.CD_CONTA)\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c2191",
   "metadata": {},
   "source": [
    "## **Execução Principal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b83e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rpJIjd_8lvn",
    "outputId": "07b5965f-cbc9-4af6-9270-1a43337d4a8a"
   },
   "outputs": [],
   "source": [
    "def executaExperimento():\n",
    "    inicializaProveniencia()\n",
    "    df_obinvest = criar_dataset_obinvest()\n",
    "    analiseInicialDataset(df_obinvest)\n",
    "    analiseEstatisticaDataset(df_obinvest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if(checkingEnvironmentVersions(True)):\n",
    "        executaExperimento()\n",
    "        \n",
    "main() # condição suspensa para poder rodar no notebook local\n",
    "\n",
    "Image(\"DRE-CVM-PROV.png\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "drecvm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
